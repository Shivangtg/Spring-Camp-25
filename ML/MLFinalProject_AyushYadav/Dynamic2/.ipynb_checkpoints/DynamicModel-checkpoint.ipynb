{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64381a80-7311-44ef-8da4-2bc9de4a363f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ec76220-c381-48cc-9304-19acbc884d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_excel(\"DynamicDataset2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a233ce9c-d5cb-40e1-839a-5ccbe0c718d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>-0.022923</th>\n",
       "      <th>-0.074436</th>\n",
       "      <th>-0.022171</th>\n",
       "      <th>-0.028323</th>\n",
       "      <th>-0.151704</th>\n",
       "      <th>-0.045609</th>\n",
       "      <th>-0.038705</th>\n",
       "      <th>...</th>\n",
       "      <th>-0.038046</th>\n",
       "      <th>-0.214297</th>\n",
       "      <th>-0.103738</th>\n",
       "      <th>-0.039037</th>\n",
       "      <th>-0.248888</th>\n",
       "      <th>-0.116504</th>\n",
       "      <th>-0.034625</th>\n",
       "      <th>-0.279146</th>\n",
       "      <th>-0.131163</th>\n",
       "      <th>-0.031947</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.019811</td>\n",
       "      <td>-0.061122</td>\n",
       "      <td>-0.034406</td>\n",
       "      <td>-0.026764</td>\n",
       "      <td>-0.125523</td>\n",
       "      <td>-0.069354</td>\n",
       "      <td>-0.038078</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083983</td>\n",
       "      <td>-0.193951</td>\n",
       "      <td>0.033002</td>\n",
       "      <td>-0.096462</td>\n",
       "      <td>-0.234293</td>\n",
       "      <td>0.032076</td>\n",
       "      <td>-0.097002</td>\n",
       "      <td>-0.265645</td>\n",
       "      <td>0.032857</td>\n",
       "      <td>-0.097469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.010526</td>\n",
       "      <td>-0.060849</td>\n",
       "      <td>-0.027154</td>\n",
       "      <td>-0.006335</td>\n",
       "      <td>-0.128390</td>\n",
       "      <td>-0.050885</td>\n",
       "      <td>-0.003802</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072530</td>\n",
       "      <td>-0.195837</td>\n",
       "      <td>0.031124</td>\n",
       "      <td>-0.083275</td>\n",
       "      <td>-0.235021</td>\n",
       "      <td>0.027011</td>\n",
       "      <td>-0.083764</td>\n",
       "      <td>-0.266971</td>\n",
       "      <td>0.024746</td>\n",
       "      <td>-0.084021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.017019</td>\n",
       "      <td>-0.053103</td>\n",
       "      <td>-0.034242</td>\n",
       "      <td>-0.013075</td>\n",
       "      <td>-0.105614</td>\n",
       "      <td>-0.060508</td>\n",
       "      <td>-0.008712</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083194</td>\n",
       "      <td>-0.186807</td>\n",
       "      <td>0.023796</td>\n",
       "      <td>-0.097415</td>\n",
       "      <td>-0.228774</td>\n",
       "      <td>0.024389</td>\n",
       "      <td>-0.099393</td>\n",
       "      <td>-0.262933</td>\n",
       "      <td>0.025175</td>\n",
       "      <td>-0.100647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.007565</td>\n",
       "      <td>-0.079868</td>\n",
       "      <td>-0.018892</td>\n",
       "      <td>0.009276</td>\n",
       "      <td>-0.153492</td>\n",
       "      <td>-0.037187</td>\n",
       "      <td>0.023541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059465</td>\n",
       "      <td>-0.150186</td>\n",
       "      <td>-0.137818</td>\n",
       "      <td>-0.071906</td>\n",
       "      <td>-0.190198</td>\n",
       "      <td>-0.132673</td>\n",
       "      <td>-0.070480</td>\n",
       "      <td>-0.218138</td>\n",
       "      <td>-0.126389</td>\n",
       "      <td>-0.068668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.008368</td>\n",
       "      <td>-0.070461</td>\n",
       "      <td>-0.024282</td>\n",
       "      <td>0.011550</td>\n",
       "      <td>-0.144013</td>\n",
       "      <td>-0.040488</td>\n",
       "      <td>0.032351</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057583</td>\n",
       "      <td>-0.213338</td>\n",
       "      <td>0.007031</td>\n",
       "      <td>-0.071417</td>\n",
       "      <td>-0.255335</td>\n",
       "      <td>-0.002325</td>\n",
       "      <td>-0.078993</td>\n",
       "      <td>-0.289609</td>\n",
       "      <td>-0.011637</td>\n",
       "      <td>-0.083551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.061613</td>\n",
       "      <td>-0.039756</td>\n",
       "      <td>-0.017649</td>\n",
       "      <td>-0.112823</td>\n",
       "      <td>-0.115034</td>\n",
       "      <td>-0.022929</td>\n",
       "      <td>-0.143908</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013917</td>\n",
       "      <td>0.039951</td>\n",
       "      <td>-0.277698</td>\n",
       "      <td>-0.020642</td>\n",
       "      <td>0.044205</td>\n",
       "      <td>-0.314799</td>\n",
       "      <td>-0.017931</td>\n",
       "      <td>0.045244</td>\n",
       "      <td>-0.349283</td>\n",
       "      <td>-0.015437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.063050</td>\n",
       "      <td>-0.034229</td>\n",
       "      <td>-0.020114</td>\n",
       "      <td>-0.119986</td>\n",
       "      <td>-0.102091</td>\n",
       "      <td>-0.026481</td>\n",
       "      <td>-0.157640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014769</td>\n",
       "      <td>-0.025758</td>\n",
       "      <td>-0.293729</td>\n",
       "      <td>-0.025278</td>\n",
       "      <td>-0.028198</td>\n",
       "      <td>-0.338051</td>\n",
       "      <td>-0.029886</td>\n",
       "      <td>-0.030513</td>\n",
       "      <td>-0.380357</td>\n",
       "      <td>-0.033304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.065787</td>\n",
       "      <td>-0.019948</td>\n",
       "      <td>-0.019395</td>\n",
       "      <td>-0.127176</td>\n",
       "      <td>-0.072450</td>\n",
       "      <td>-0.025080</td>\n",
       "      <td>-0.165901</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029625</td>\n",
       "      <td>0.032480</td>\n",
       "      <td>-0.306014</td>\n",
       "      <td>-0.039501</td>\n",
       "      <td>0.033142</td>\n",
       "      <td>-0.357223</td>\n",
       "      <td>-0.038088</td>\n",
       "      <td>0.033959</td>\n",
       "      <td>-0.403801</td>\n",
       "      <td>-0.034505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.039971</td>\n",
       "      <td>-0.047113</td>\n",
       "      <td>-0.025976</td>\n",
       "      <td>-0.064995</td>\n",
       "      <td>-0.120803</td>\n",
       "      <td>-0.041172</td>\n",
       "      <td>-0.061650</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027740</td>\n",
       "      <td>0.140397</td>\n",
       "      <td>-0.204115</td>\n",
       "      <td>-0.050214</td>\n",
       "      <td>0.178106</td>\n",
       "      <td>-0.225679</td>\n",
       "      <td>-0.058034</td>\n",
       "      <td>0.212669</td>\n",
       "      <td>-0.241757</td>\n",
       "      <td>-0.059332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.048337</td>\n",
       "      <td>-0.054349</td>\n",
       "      <td>-0.019346</td>\n",
       "      <td>-0.076013</td>\n",
       "      <td>-0.148298</td>\n",
       "      <td>-0.026635</td>\n",
       "      <td>-0.090658</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026219</td>\n",
       "      <td>0.121306</td>\n",
       "      <td>-0.232849</td>\n",
       "      <td>-0.048252</td>\n",
       "      <td>0.155920</td>\n",
       "      <td>-0.261255</td>\n",
       "      <td>-0.059504</td>\n",
       "      <td>0.185430</td>\n",
       "      <td>-0.286140</td>\n",
       "      <td>-0.065862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>346 rows × 1890 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   0.1   0.2  -0.022923  -0.074436  -0.022171  -0.028323  -0.151704  \\\n",
       "0     0     0     0  -0.019811  -0.061122  -0.034406  -0.026764  -0.125523   \n",
       "1     0     0     0  -0.010526  -0.060849  -0.027154  -0.006335  -0.128390   \n",
       "2     0     0     0  -0.017019  -0.053103  -0.034242  -0.013075  -0.105614   \n",
       "3     0     0     0  -0.007565  -0.079868  -0.018892   0.009276  -0.153492   \n",
       "4     0     0     0  -0.008368  -0.070461  -0.024282   0.011550  -0.144013   \n",
       "..   ..   ...   ...        ...        ...        ...        ...        ...   \n",
       "341   0     0     0  -0.061613  -0.039756  -0.017649  -0.112823  -0.115034   \n",
       "342   0     0     0  -0.063050  -0.034229  -0.020114  -0.119986  -0.102091   \n",
       "343   0     0     0  -0.065787  -0.019948  -0.019395  -0.127176  -0.072450   \n",
       "344   0     0     0  -0.039971  -0.047113  -0.025976  -0.064995  -0.120803   \n",
       "345   0     0     0  -0.048337  -0.054349  -0.019346  -0.076013  -0.148298   \n",
       "\n",
       "     -0.045609  -0.038705  ...  -0.038046  -0.214297  -0.103738  -0.039037  \\\n",
       "0    -0.069354  -0.038078  ...  -0.083983  -0.193951   0.033002  -0.096462   \n",
       "1    -0.050885  -0.003802  ...  -0.072530  -0.195837   0.031124  -0.083275   \n",
       "2    -0.060508  -0.008712  ...  -0.083194  -0.186807   0.023796  -0.097415   \n",
       "3    -0.037187   0.023541  ...  -0.059465  -0.150186  -0.137818  -0.071906   \n",
       "4    -0.040488   0.032351  ...  -0.057583  -0.213338   0.007031  -0.071417   \n",
       "..         ...        ...  ...        ...        ...        ...        ...   \n",
       "341  -0.022929  -0.143908  ...  -0.013917   0.039951  -0.277698  -0.020642   \n",
       "342  -0.026481  -0.157640  ...  -0.014769  -0.025758  -0.293729  -0.025278   \n",
       "343  -0.025080  -0.165901  ...  -0.029625   0.032480  -0.306014  -0.039501   \n",
       "344  -0.041172  -0.061650  ...  -0.027740   0.140397  -0.204115  -0.050214   \n",
       "345  -0.026635  -0.090658  ...  -0.026219   0.121306  -0.232849  -0.048252   \n",
       "\n",
       "     -0.248888  -0.116504  -0.034625  -0.279146  -0.131163  -0.031947  \n",
       "0    -0.234293   0.032076  -0.097002  -0.265645   0.032857  -0.097469  \n",
       "1    -0.235021   0.027011  -0.083764  -0.266971   0.024746  -0.084021  \n",
       "2    -0.228774   0.024389  -0.099393  -0.262933   0.025175  -0.100647  \n",
       "3    -0.190198  -0.132673  -0.070480  -0.218138  -0.126389  -0.068668  \n",
       "4    -0.255335  -0.002325  -0.078993  -0.289609  -0.011637  -0.083551  \n",
       "..         ...        ...        ...        ...        ...        ...  \n",
       "341   0.044205  -0.314799  -0.017931   0.045244  -0.349283  -0.015437  \n",
       "342  -0.028198  -0.338051  -0.029886  -0.030513  -0.380357  -0.033304  \n",
       "343   0.033142  -0.357223  -0.038088   0.033959  -0.403801  -0.034505  \n",
       "344   0.178106  -0.225679  -0.058034   0.212669  -0.241757  -0.059332  \n",
       "345   0.155920  -0.261255  -0.059504   0.185430  -0.286140  -0.065862  \n",
       "\n",
       "[346 rows x 1890 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70ce5356-97cc-4225-959f-311e3e8a84ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.values\n",
    "X = X.reshape(-1, 30, 63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85754a2e-05f7-4d02-924e-29a6d45ce13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(346, 30, 63)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "236d7b1a-e344-4625-bbf0-d46d142c0825",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.read_excel(\"Labels2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71480155-1b54-4a61-bc9b-2de0167bd15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>346 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "..  ..\n",
       "341  1\n",
       "342  1\n",
       "343  1\n",
       "344  1\n",
       "345  1\n",
       "\n",
       "[346 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be16a15a-885c-4857-accb-4cfcb75c8679",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "650b1bde-3c8c-43a2-9ac2-1a510131a754",
   "metadata": {},
   "outputs": [],
   "source": [
    "model21 = Sequential([\n",
    "    LSTM(128, return_sequences=True, input_shape=(30, 63)),\n",
    "    Dropout(0.2),\n",
    "    LSTM(128),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ded3928-3afe-4081-ad1d-97c33099ecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model21.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbfad565-f44a-4140-8ed0-db9cd8941412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 162ms/step - accuracy: 0.8599 - loss: 0.5833 - val_accuracy: 1.0000 - val_loss: 0.1176\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9979 - loss: 0.0656 - val_accuracy: 0.7800 - val_loss: 1.2711\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9017 - loss: 0.4902 - val_accuracy: 1.0000 - val_loss: 0.0026\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 0.0046\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 0.0108\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9952 - loss: 0.0092 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 0.0026\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 8.9053e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 9.9016e-04 - val_accuracy: 1.0000 - val_loss: 7.3704e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 7.8264e-04 - val_accuracy: 1.0000 - val_loss: 6.1883e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 6.9152e-04 - val_accuracy: 1.0000 - val_loss: 5.3234e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 6.4603e-04 - val_accuracy: 1.0000 - val_loss: 4.6393e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 5.0152e-04 - val_accuracy: 1.0000 - val_loss: 4.0923e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 5.2585e-04 - val_accuracy: 1.0000 - val_loss: 3.6396e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 3.7559e-04 - val_accuracy: 1.0000 - val_loss: 3.2746e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 3.5459e-04 - val_accuracy: 1.0000 - val_loss: 2.9643e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 3.2508e-04 - val_accuracy: 1.0000 - val_loss: 2.7018e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 3.2595e-04 - val_accuracy: 1.0000 - val_loss: 2.4674e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 3.1538e-04 - val_accuracy: 1.0000 - val_loss: 2.2485e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 2.5329e-04 - val_accuracy: 1.0000 - val_loss: 2.0642e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 2.3781e-04 - val_accuracy: 1.0000 - val_loss: 1.9057e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.2891e-04 - val_accuracy: 1.0000 - val_loss: 1.7608e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 2.0886e-04 - val_accuracy: 1.0000 - val_loss: 1.6333e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 1.8715e-04 - val_accuracy: 1.0000 - val_loss: 1.5194e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.9285e-04 - val_accuracy: 1.0000 - val_loss: 1.4185e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 1.6379e-04 - val_accuracy: 1.0000 - val_loss: 1.3286e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.5365e-04 - val_accuracy: 1.0000 - val_loss: 1.2442e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 1.6186e-04 - val_accuracy: 1.0000 - val_loss: 1.1614e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 1.4400e-04 - val_accuracy: 1.0000 - val_loss: 1.0924e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.3875e-04 - val_accuracy: 1.0000 - val_loss: 1.0309e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.2522e-04 - val_accuracy: 1.0000 - val_loss: 9.7439e-05\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 1.3512e-04 - val_accuracy: 1.0000 - val_loss: 9.2179e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 1.0381e-04 - val_accuracy: 1.0000 - val_loss: 8.7459e-05\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 1.1269e-04 - val_accuracy: 1.0000 - val_loss: 8.2906e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 1.0330e-04 - val_accuracy: 1.0000 - val_loss: 7.8721e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 1.0653e-04 - val_accuracy: 1.0000 - val_loss: 7.4784e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 1.1192e-04 - val_accuracy: 1.0000 - val_loss: 7.0974e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 9.1456e-05 - val_accuracy: 1.0000 - val_loss: 6.7479e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 8.1326e-05 - val_accuracy: 1.0000 - val_loss: 6.4415e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 7.4454e-05 - val_accuracy: 1.0000 - val_loss: 6.1557e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 7.2717e-05 - val_accuracy: 1.0000 - val_loss: 5.8840e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 6.5009e-05 - val_accuracy: 1.0000 - val_loss: 5.6427e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 6.7651e-05 - val_accuracy: 1.0000 - val_loss: 5.4173e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 7.0851e-05 - val_accuracy: 1.0000 - val_loss: 5.1971e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 6.5409e-05 - val_accuracy: 1.0000 - val_loss: 4.9833e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 6.2022e-05 - val_accuracy: 1.0000 - val_loss: 4.7870e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 6.1513e-05 - val_accuracy: 1.0000 - val_loss: 4.6034e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 6.2080e-05 - val_accuracy: 1.0000 - val_loss: 4.4211e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 5.3797e-05 - val_accuracy: 1.0000 - val_loss: 4.2454e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 4.7652e-05 - val_accuracy: 1.0000 - val_loss: 4.0820e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 5.2790e-05 - val_accuracy: 1.0000 - val_loss: 3.9286e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 5.9162e-05 - val_accuracy: 1.0000 - val_loss: 3.7778e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 4.8178e-05 - val_accuracy: 1.0000 - val_loss: 3.6429e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 4.1425e-05 - val_accuracy: 1.0000 - val_loss: 3.5219e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 4.7529e-05 - val_accuracy: 1.0000 - val_loss: 3.4063e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 4.7413e-05 - val_accuracy: 1.0000 - val_loss: 3.2947e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 4.3476e-05 - val_accuracy: 1.0000 - val_loss: 3.1907e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 4.2778e-05 - val_accuracy: 1.0000 - val_loss: 3.0911e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.8875e-05 - val_accuracy: 1.0000 - val_loss: 2.9944e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 3.8452e-05 - val_accuracy: 1.0000 - val_loss: 2.9014e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 3.4121e-05 - val_accuracy: 1.0000 - val_loss: 2.8168e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 3.6690e-05 - val_accuracy: 1.0000 - val_loss: 2.7305e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 3.4665e-05 - val_accuracy: 1.0000 - val_loss: 2.6476e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 3.7551e-05 - val_accuracy: 1.0000 - val_loss: 2.5577e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 3.5661e-05 - val_accuracy: 1.0000 - val_loss: 2.4782e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 3.6547e-05 - val_accuracy: 1.0000 - val_loss: 2.4036e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.3032e-05 - val_accuracy: 1.0000 - val_loss: 2.3311e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.0631e-05 - val_accuracy: 1.0000 - val_loss: 2.2617e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.9451e-05 - val_accuracy: 1.0000 - val_loss: 2.1989e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 2.7676e-05 - val_accuracy: 1.0000 - val_loss: 2.1391e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 2.9687e-05 - val_accuracy: 1.0000 - val_loss: 2.0796e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 2.7465e-05 - val_accuracy: 1.0000 - val_loss: 2.0229e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 2.3111e-05 - val_accuracy: 1.0000 - val_loss: 1.9696e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 2.3854e-05 - val_accuracy: 1.0000 - val_loss: 1.9167e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 2.3017e-05 - val_accuracy: 1.0000 - val_loss: 1.8654e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 2.8063e-05 - val_accuracy: 1.0000 - val_loss: 1.8153e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 2.1548e-05 - val_accuracy: 1.0000 - val_loss: 1.7681e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.2648e-05 - val_accuracy: 1.0000 - val_loss: 1.7261e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 2.1510e-05 - val_accuracy: 1.0000 - val_loss: 1.6869e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 2.2814e-05 - val_accuracy: 1.0000 - val_loss: 1.6475e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 2.4690e-05 - val_accuracy: 1.0000 - val_loss: 1.6080e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 2.1255e-05 - val_accuracy: 1.0000 - val_loss: 1.5699e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 2.1310e-05 - val_accuracy: 1.0000 - val_loss: 1.5305e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 1.8420e-05 - val_accuracy: 1.0000 - val_loss: 1.4954e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 1.9716e-05 - val_accuracy: 1.0000 - val_loss: 1.4630e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 1.9417e-05 - val_accuracy: 1.0000 - val_loss: 1.4328e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.8753e-05 - val_accuracy: 1.0000 - val_loss: 1.4024e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 1.7052e-05 - val_accuracy: 1.0000 - val_loss: 1.3709e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 1.9588e-05 - val_accuracy: 1.0000 - val_loss: 1.3388e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 1.6893e-05 - val_accuracy: 1.0000 - val_loss: 1.3094e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 1.9988e-05 - val_accuracy: 1.0000 - val_loss: 1.2806e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 1.6227e-05 - val_accuracy: 1.0000 - val_loss: 1.2531e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.8395e-05 - val_accuracy: 1.0000 - val_loss: 1.2262e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 1.4948e-05 - val_accuracy: 1.0000 - val_loss: 1.2016e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 1.7636e-05 - val_accuracy: 1.0000 - val_loss: 1.1768e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 1.6695e-05 - val_accuracy: 1.0000 - val_loss: 1.1516e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 1.6448e-05 - val_accuracy: 1.0000 - val_loss: 1.1251e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x245eea741d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model21.fit(X_train, y_train, epochs=100, batch_size=32,validation_split=.18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02b7d47c-2331-46da-8e7f-07350695ab2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 212ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model21.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa44dc22-167c-4840-9687-78dc7dfef953",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalPerdictions=(predictions > 0.5).astype(int)  # Convert to 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1db771f-be0c-4c59-b30b-0fdd5a4a6b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalPredictions=finalPerdictions.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7caf14f2-77f6-4f79-b578-01b83a8dcbe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalPredictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7389d346-bedc-489f-a525-e54627198fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_testFinal=y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72ba3783-29c1-4472-96d1-577db0bc5c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yFinal=y_testFinal.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dce925d7-a16f-4ddf-b8bb-cd40acf991c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=0\n",
    "for i in range(67):\n",
    "    if(finalPredictions[i] ==yFinal[i]):\n",
    "        x=x+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e54a593d-4dc6-4fae-b6d9-1a09a510acb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31e7096b-b345-4f8f-b36b-945ab89a17a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model21.save(\"DynamicModel21.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
