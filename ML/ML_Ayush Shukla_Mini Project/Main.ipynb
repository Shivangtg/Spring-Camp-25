{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.18.0)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ayush\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (75.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install setuptools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.10.21)\n",
      "Requirement already satisfied: absl-py in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (25.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (25.2.10)\n",
      "Requirement already satisfied: jax in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (0.5.0)\n",
      "Requirement already satisfied: jaxlib in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (0.5.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (3.9.2)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (1.26.4)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (4.11.0.86)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (4.25.6)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (0.5.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (0.2.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: ml_dtypes>=0.4.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jax->mediapipe) (0.4.1)\n",
      "Requirement already satisfied: opt_einsum in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.11.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jax->mediapipe) (1.15.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->mediapipe) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->mediapipe) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->mediapipe) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->mediapipe) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->mediapipe) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->mediapipe) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install mediapipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Static Guesture dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures=[\"open_palm\",\"thumbs_up\",\"thumbs_down\",\"victory\",\"fist\",\"spiderman\",\"fuck_off\"] #Static Guestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-by-one capture the datasets and save them.\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "\n",
    "gesture_name=\"fuck_off\" \n",
    "def capture_images(gesture_name, num_images=500, delay=0.2):\n",
    "    save_path = f\"data/static/{gesture_name}\"\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)  # Open webcam\n",
    "    count = 0\n",
    "\n",
    "    while count < num_images:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to capture image\")\n",
    "            break\n",
    "\n",
    "        # Flip the image to create the inverted version\n",
    "        flipped_frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Display the live feed\n",
    "        cv2.putText(frame, f\"Capturing {gesture_name} ({count}/{num_images})\",\n",
    "                    (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        cv2.imshow(\"Capture Gesture\", frame)\n",
    "\n",
    "        # Save both original and flipped images\n",
    "        cv2.imwrite(f\"{save_path}/{count}.jpg\", frame)  # Original\n",
    "        cv2.imwrite(f\"{save_path}/{count}_flipped.jpg\", flipped_frame)  # Flipped version\n",
    "\n",
    "        count += 1\n",
    "        time.sleep(delay)  # Delay between captures\n",
    "\n",
    "        # Press 'q' to stop early\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Run the function\n",
    "capture_images(gesture_name, num_images=500, delay=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hand landmark using media pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Hand landmarks extracted and saved to CSV!\n"
     ]
    }
   ],
   "source": [
    "#Extracting the landmarks from the images and saving them to a CSV file.\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Initialize Mediapipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5)\n",
    "\n",
    "# Define dataset path and CSV file\n",
    "dataset_path = \"C:\\\\Users\\\\AYUSH\\\\OneDrive\\\\Desktop\\\\CPP\\\\Machine Learning\\\\data\\\\static\"\n",
    "\n",
    "csv_file = \"hand_landmarks.csv\"\n",
    "\n",
    "# Create CSV file and write header\n",
    "with open(csv_file, mode='w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    header = [\"gesture\"] + [f\"x{i},y{i},z{i}\" for i in range(21)]  # 21 landmarks\n",
    "    writer.writerow(header)\n",
    "\n",
    "# Process each gesture folder\n",
    "for gesture_name in os.listdir(dataset_path):\n",
    "    gesture_path = os.path.join(dataset_path, gesture_name)\n",
    "    \n",
    "    if not os.path.isdir(gesture_path):\n",
    "        continue\n",
    "\n",
    "    for img_name in os.listdir(gesture_path):\n",
    "        img_path = os.path.join(gesture_path, img_name)\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            continue\n",
    "\n",
    "        # Convert to RGB and process with Mediapipe\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(rgb_image)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # Extract landmarks\n",
    "                landmarks = []\n",
    "                for lm in hand_landmarks.landmark:\n",
    "                    landmarks.extend([lm.x, lm.y, lm.z])  # Flatten (x, y, z)\n",
    "\n",
    "                # Save to CSV\n",
    "                with open(csv_file, mode='a', newline='') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow([gesture_name] + landmarks)\n",
    "\n",
    "print(\"✅ Hand landmarks extracted and saved to CSV!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data Loaded and Preprocessed!\n",
      "Total Samples: 5718, Training: 4574, Validation: 1144\n",
      "X_train shape: (4574, 21), y_train shape: (4574,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"hand_landmarks.csv\")\n",
    "\n",
    "# Separate features (landmarks) and labels (gesture names)\n",
    "X = df.iloc[:, 1:].values  # Hand landmarks (exclude gesture column)\n",
    "y = df.iloc[:, 0].values  # Gesture names\n",
    "\n",
    "# Convert gesture labels to numbers\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#np.save(\"label_classes.npy\", label_encoder.classes_)\n",
    "\n",
    "print(\"✅ Data Loaded and Preprocessed!\")\n",
    "print(f\"Total Samples: {len(df)}, Training: {len(X_train)}, Validation: {len(X_val)}\")\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a neural network to classify the gestures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train: (4574, 5718), Shape of y_val: (1144, 5717)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AYUSH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 63, but received input with shape (None, 21)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 21), dtype=float32)\n  • training=True\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShape of y_train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Shape of y_val: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_val\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Train the model (Put the callback inside fit)\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Save the trained model\u001b[39;00m\n\u001b[0;32m     43\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgesture_model.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\AYUSH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\AYUSH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m    224\u001b[0m             value,\n\u001b[0;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    226\u001b[0m         }:\n\u001b[1;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m             )\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 63, but received input with shape (None, 21)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 21), dtype=float32)\n  • training=True\n  • mask=None"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    \n",
    "    Dense(128, activation='relu', input_shape=(63,)),\n",
    "    BatchNormalization(),\n",
    "    #Dropout(0.5),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    #Dropout(0.2),\n",
    "\n",
    "    Dense(32, activation='relu'),\n",
    "    #Dropout(0.2),\n",
    "\n",
    "    Dense(7, activation='softmax')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=RMSprop(learning_rate=0.001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "print(f'Shape of y_train: {y_train.shape}, Shape of y_val: {y_val.shape}')\n",
    "\n",
    "# Train the model (Put the callback inside fit)\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=50, \n",
    "                    batch_size=32, \n",
    "                    validation_data=(X_val, y_val), \n",
    "                    callbacks=[lr_scheduler])\n",
    "\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"gesture_model.keras\")\n",
    "\n",
    "print(\"✅ Model Trained and Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">231</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m231\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,672</span> (151.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m38,672\u001b[0m (151.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,143</span> (74.78 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,143\u001b[0m (74.78 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,145</span> (74.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m19,145\u001b[0m (74.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to determine if Static or Dynamic movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def isStatic(landmark_history,threshold=10):\n",
    "    if len(landmark_history)<2:\n",
    "        return True\n",
    "    distance=np.mean(np.linalg.norm(np.array(landmark_history[-1])-np.array(landmark_history[-2])))\n",
    "    return distance<threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded gesture classes: [-0.2371041  -0.22068678 -0.21517485 ...  0.1248069   0.13180147\n",
      "  0.13476376]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
      "Raw model output: [[1.3891624e-02 2.0795469e-03 9.7596258e-01 1.7071060e-03 5.5302093e-03\n",
      "  2.1913486e-06 8.2672562e-04]]\n",
      "Softmax probabilities: [[0.11684758 0.11547548 0.30580303 0.11543248 0.11587464 0.11523585\n",
      "  0.1153309 ]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Raw model output: [[3.6266844e-08 3.1929314e-06 9.9999666e-01 4.8083901e-08 1.4639498e-08\n",
      "  8.9282054e-11 1.2173392e-07]]\n",
      "Softmax probabilities: [[0.11470158 0.11470195 0.31179014 0.11470158 0.11470158 0.11470158\n",
      "  0.11470159]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Raw model output: [[8.4088754e-08 3.1937807e-06 9.9999654e-01 5.2712814e-08 1.6675825e-09\n",
      "  7.1568203e-11 7.9420573e-08]]\n",
      "Softmax probabilities: [[0.11470158 0.11470194 0.3117901  0.11470158 0.11470158 0.11470158\n",
      "  0.11470158]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Raw model output: [[7.7101184e-08 3.6436629e-06 9.9999607e-01 8.0102552e-08 1.9316377e-09\n",
      "  7.2711018e-11 1.3786887e-07]]\n",
      "Softmax probabilities: [[0.11470159 0.114702   0.31179    0.11470159 0.11470158 0.11470158\n",
      "  0.11470161]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Raw model output: [[1.0020420e-07 2.7376288e-06 9.9999690e-01 1.1005887e-07 2.3976083e-09\n",
      "  7.7814713e-11 1.3499994e-07]]\n",
      "Softmax probabilities: [[0.11470158 0.11470188 0.3117902  0.11470158 0.11470157 0.11470157\n",
      "  0.11470158]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Raw model output: [[8.3209599e-08 1.8871242e-06 9.9999774e-01 1.0179586e-07 2.2982511e-09\n",
      "  5.8130809e-11 9.2740478e-08]]\n",
      "Softmax probabilities: [[0.11470158 0.11470178 0.31179044 0.11470158 0.11470156 0.11470156\n",
      "  0.11470158]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Raw model output: [[5.8267808e-08 1.2679160e-06 9.9999845e-01 5.2016773e-08 2.1430733e-09\n",
      "  3.3388296e-11 7.5172949e-08]]\n",
      "Softmax probabilities: [[0.11470155 0.11470169 0.31179062 0.11470155 0.11470155 0.11470155\n",
      "  0.11470155]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Raw model output: [[9.6640385e-08 1.2873938e-06 9.9999833e-01 9.6152050e-08 2.8691989e-09\n",
      "  5.5127843e-11 7.4875295e-08]]\n",
      "Softmax probabilities: [[0.11470155 0.11470169 0.31179056 0.11470155 0.11470153 0.11470153\n",
      "  0.11470154]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Raw model output: [[7.9399392e-08 9.5669554e-07 9.9999869e-01 1.0259004e-07 3.1137146e-09\n",
      "  4.8217090e-11 6.7182995e-08]]\n",
      "Softmax probabilities: [[0.11470154 0.11470164 0.31179065 0.11470155 0.11470153 0.11470153\n",
      "  0.11470154]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Raw model output: [[2.3971879e-06 1.5681670e-06 9.9999559e-01 3.3543441e-07 1.2035495e-08\n",
      "  2.0453648e-10 1.2555719e-07]]\n",
      "Softmax probabilities: [[0.11470187 0.11470177 0.31178987 0.11470164 0.1147016  0.1147016\n",
      "  0.11470161]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Raw model output: [[5.7122365e-09 2.0484780e-05 9.9997747e-01 3.1261067e-07 2.9993155e-10\n",
      "  2.0787549e-09 1.7877803e-06]]\n",
      "Softmax probabilities: [[0.11470201 0.11470436 0.31178534 0.11470205 0.11470201 0.11470201\n",
      "  0.11470222]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Raw model output: [[5.3913243e-09 2.8844226e-05 9.9996769e-01 2.9887400e-07 4.5938223e-10\n",
      "  1.9303785e-09 3.1657783e-06]]\n",
      "Softmax probabilities: [[0.11470222 0.11470553 0.31178287 0.11470225 0.11470222 0.11470222\n",
      "  0.11470259]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Raw model output: [[3.0570817e-09 1.4479302e-05 9.9998415e-01 1.4271509e-07 1.6319986e-10\n",
      "  2.1242899e-09 1.2393233e-06]]\n",
      "Softmax probabilities: [[0.11470187 0.11470352 0.311787   0.11470187 0.11470187 0.11470187\n",
      "  0.114702  ]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Raw model output: [[1.8106866e-06 5.1614264e-04 9.9944049e-01 9.6203735e-07 2.5708868e-08\n",
      "  1.0072387e-08 4.0654042e-05]]\n",
      "Softmax probabilities: [[0.11471434 0.11477336 0.3116509  0.11471424 0.11471413 0.11471413\n",
      "  0.11471879]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Raw model output: [[6.7547294e-03 1.0083869e-02 9.7346807e-01 6.6522334e-05 4.9939467e-07\n",
      "  1.1063527e-06 9.6252458e-03]]\n",
      "Softmax probabilities: [[0.11607163 0.11645868 0.3051858  0.11529791 0.11529029 0.11529037\n",
      "  0.11640529]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Raw model output: [[9.9965763e-01 6.3967462e-05 3.4739354e-05 4.0094055e-06 2.3004656e-08\n",
      "  3.5429127e-07 2.3935047e-04]]\n",
      "Softmax probabilities: [[0.31170526 0.11471657 0.11471322 0.11470969 0.11470924 0.11470927\n",
      "  0.1147367 ]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Raw model output: [[9.9962699e-01 7.9578276e-05 3.2233209e-05 6.4434576e-06 3.2412565e-08\n",
      "  5.6132620e-07 2.5414533e-04]]\n",
      "Softmax probabilities: [[0.3116976  0.11471906 0.11471362 0.11471067 0.11470994 0.11471\n",
      "  0.11473909]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Raw model output: [[9.996030e-01 5.149795e-05 3.455359e-05 9.105060e-06 4.662706e-08\n",
      "  9.296332e-07 3.010174e-04]]\n",
      "Softmax probabilities: [[0.3116916  0.11471639 0.11471445 0.11471152 0.11471048 0.11471058\n",
      "  0.11474501]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Raw model output: [[9.9964273e-01 4.7611735e-05 3.3321117e-05 7.6342185e-06 4.4280192e-08\n",
      "  8.0880210e-07 2.6789019e-04]]\n",
      "Softmax probabilities: [[0.31170154 0.11471504 0.11471339 0.11471045 0.11470958 0.11470967\n",
      "  0.1147403 ]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Raw model output: [[9.9968660e-01 5.4441811e-05 3.1912190e-05 6.7369365e-06 4.4494559e-08\n",
      "  8.8581584e-07 2.1943125e-04]]\n",
      "Softmax probabilities: [[0.31171253 0.11471483 0.11471225 0.11470935 0.11470859 0.11470869\n",
      "  0.11473376]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Raw model output: [[9.9961591e-01 1.1066849e-04 3.3658634e-05 9.2188866e-06 5.6440033e-08\n",
      "  8.5240151e-07 2.2968600e-04]]\n",
      "Softmax probabilities: [[0.31169483 0.11472288 0.11471405 0.11471124 0.11471019 0.11471027\n",
      "  0.11473653]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Raw model output: [[4.4880036e-08 1.8688746e-05 9.9997950e-01 9.0453412e-08 1.9641483e-08\n",
      "  8.4340354e-11 1.5480555e-06]]\n",
      "Softmax probabilities: [[0.11470199 0.11470412 0.31178588 0.11470199 0.11470198 0.11470198\n",
      "  0.11470215]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Raw model output: [[1.2822228e-07 3.9138034e-05 9.9995863e-01 6.6701887e-08 3.1026126e-08\n",
      "  9.1215417e-11 2.0817938e-06]]\n",
      "Softmax probabilities: [[0.11470246 0.11470693 0.31178063 0.11470245 0.11470245 0.11470243\n",
      "  0.11470268]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Raw model output: [[1.3635872e-07 3.2220276e-05 9.9996567e-01 7.0144544e-08 2.6237712e-08\n",
      "  9.5158458e-11 1.8637061e-06]]\n",
      "Softmax probabilities: [[0.11470229 0.11470598 0.3117824  0.11470228 0.11470228 0.11470228\n",
      "  0.1147025 ]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Raw model output: [[1.2322319e-07 2.7436779e-05 9.9997115e-01 5.5119067e-08 1.8250612e-08\n",
      "  7.2211383e-11 1.1325722e-06]]\n",
      "Softmax probabilities: [[0.11470217 0.11470531 0.3117838  0.11470217 0.11470217 0.11470217\n",
      "  0.1147023 ]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Raw model output: [[1.3727356e-07 3.0354684e-05 9.9996805e-01 5.8538507e-08 2.3493834e-08\n",
      "  7.9936113e-11 1.4280711e-06]]\n",
      "Softmax probabilities: [[0.11470223 0.1147057  0.31178296 0.11470222 0.11470221 0.11470221\n",
      "  0.11470238]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Raw model output: [[1.3168619e-07 2.7375940e-05 9.9997139e-01 5.1427218e-08 2.1883164e-08\n",
      "  7.9028152e-11 1.0617375e-06]]\n",
      "Softmax probabilities: [[0.11470217 0.11470529 0.31178382 0.11470216 0.11470215 0.11470215\n",
      "  0.11470227]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Raw model output: [[5.0595919e-08 1.6360047e-05 9.9998260e-01 5.6615161e-08 1.5027700e-08\n",
      "  6.2477287e-11 7.9893294e-07]]\n",
      "Softmax probabilities: [[0.1147019  0.11470377 0.31178662 0.1147019  0.1147019  0.1147019\n",
      "  0.11470198]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Raw model output: [[4.6683372e-08 1.3161454e-05 9.9998593e-01 5.1639002e-08 1.3055961e-08\n",
      "  6.1525535e-11 6.9703691e-07]]\n",
      "Softmax probabilities: [[0.11470182 0.11470333 0.31178746 0.11470182 0.11470181 0.11470181\n",
      "  0.1147019 ]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Raw model output: [[4.4686267e-08 1.4956502e-05 9.9998426e-01 3.7547160e-08 1.2759070e-08\n",
      "  5.9541122e-11 7.1797029e-07]]\n",
      "Softmax probabilities: [[0.11470185 0.11470357 0.311787   0.11470185 0.11470184 0.11470184\n",
      "  0.11470193]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Raw model output: [[4.5194678e-08 1.6051335e-05 9.9998295e-01 4.0357612e-08 1.4435253e-08\n",
      "  6.4016771e-11 8.1773669e-07]]\n",
      "Softmax probabilities: [[0.1147019  0.11470372 0.3117867  0.1147019  0.11470188 0.11470188\n",
      "  0.11470199]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Raw model output: [[4.3094243e-08 1.2229455e-05 9.9998713e-01 4.1922728e-08 1.1060575e-08\n",
      "  5.6536234e-11 6.2308067e-07]]\n",
      "Softmax probabilities: [[0.11470179 0.1147032  0.31178775 0.11470179 0.11470179 0.11470179\n",
      "  0.11470186]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Raw model output: [[3.7354404e-08 1.2111475e-05 9.9998724e-01 2.8986182e-08 1.4584289e-08\n",
      "  5.0976768e-11 6.1172835e-07]]\n",
      "Softmax probabilities: [[0.11470179 0.11470318 0.31178778 0.11470179 0.11470179 0.11470179\n",
      "  0.11470186]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Raw model output: [[6.7016463e-09 1.8133082e-05 1.7418619e-05 2.0704118e-08 8.4830258e-09\n",
      "  8.1293878e-09 9.9996448e-01]]\n",
      "Softmax probabilities: [[0.11470231 0.11470439 0.1147043  0.11470231 0.11470231 0.11470231\n",
      "  0.3117821 ]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Raw model output: [[2.5833269e-09 1.3797690e-05 1.9336809e-05 1.1164907e-08 5.1025397e-09\n",
      "  3.3292651e-09 9.9996686e-01]]\n",
      "Softmax probabilities: [[0.11470225 0.11470383 0.11470447 0.11470225 0.11470225 0.11470225\n",
      "  0.3117827 ]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Raw model output: [[7.17124693e-10 6.86357680e-06 1.09017865e-05 2.49689824e-09\n",
      "  1.39232537e-09 8.90994611e-10 9.99982238e-01]]\n",
      "Softmax probabilities: [[0.1147019  0.11470269 0.11470316 0.1147019  0.1147019  0.1147019\n",
      "  0.31178653]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Raw model output: [[9.3836150e-10 7.2011344e-06 9.6380672e-06 3.3903123e-09 1.9022501e-09\n",
      "  1.2519502e-09 9.9998319e-01]]\n",
      "Softmax probabilities: [[0.11470188 0.11470271 0.11470298 0.11470188 0.11470188 0.11470188\n",
      "  0.31178677]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Raw model output: [[1.0164226e-09 7.4844470e-06 1.0257009e-05 3.8354568e-09 2.1244682e-09\n",
      "  1.2131067e-09 9.9998224e-01]]\n",
      "Softmax probabilities: [[0.1147019  0.11470277 0.11470308 0.1147019  0.1147019  0.1147019\n",
      "  0.31178653]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Raw model output: [[1.1604648e-09 7.1418935e-06 1.1400662e-05 4.6537871e-09 2.5310893e-09\n",
      "  1.6655738e-09 9.9998140e-01]]\n",
      "Softmax probabilities: [[0.11470193 0.11470275 0.11470324 0.11470193 0.11470193 0.11470193\n",
      "  0.31178635]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Raw model output: [[9.8956388e-10 7.1048412e-06 1.1679646e-05 4.8889177e-09 2.9537512e-09\n",
      "  1.6106692e-09 9.9998116e-01]]\n",
      "Softmax probabilities: [[0.11470193 0.11470275 0.11470328 0.11470193 0.11470193 0.11470193\n",
      "  0.3117863 ]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Raw model output: [[1.6786723e-09 9.8955015e-06 1.4446187e-05 5.7700436e-09 2.8913940e-09\n",
      "  1.9457496e-09 9.9997568e-01]]\n",
      "Softmax probabilities: [[0.11470205 0.11470319 0.11470371 0.11470205 0.11470205 0.11470205\n",
      "  0.3117849 ]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Raw model output: [[1.0087313e-09 7.6815149e-06 1.0942599e-05 4.6168491e-09 2.9349052e-09\n",
      "  1.4699871e-09 9.9998140e-01]]\n",
      "Softmax probabilities: [[0.11470192 0.1147028  0.11470319 0.11470192 0.11470192 0.11470192\n",
      "  0.31178632]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Raw model output: [[1.10671694e-09 7.74461023e-06 1.10368055e-05 4.84688512e-09\n",
      "  3.03547010e-09 1.52253576e-09 9.99981165e-01]]\n",
      "Softmax probabilities: [[0.11470193 0.11470283 0.1147032  0.11470193 0.11470193 0.11470193\n",
      "  0.3117863 ]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Raw model output: [[6.7850964e-10 5.7551979e-06 1.0041312e-05 4.3186659e-09 3.0860228e-09\n",
      "  1.4448513e-09 9.9998426e-01]]\n",
      "Softmax probabilities: [[0.11470186 0.11470252 0.11470301 0.11470186 0.11470186 0.11470186\n",
      "  0.31178704]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Raw model output: [[1.8766016e-08 3.4071061e-05 4.2499974e-05 6.8959757e-08 1.7747119e-08\n",
      "  1.3780723e-08 9.9992323e-01]]\n",
      "Softmax probabilities: [[0.11470324 0.11470716 0.11470812 0.11470325 0.11470324 0.11470324\n",
      "  0.31177178]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Raw model output: [[2.5959409e-08 8.9498506e-05 9.9989164e-01 9.5635357e-08 1.2849663e-08\n",
      "  1.6454023e-10 1.8750156e-05]]\n",
      "Softmax probabilities: [[0.11470395 0.11471422 0.31176385 0.11470397 0.11470395 0.11470395\n",
      "  0.1147061 ]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Raw model output: [[4.3485862e-08 9.9769022e-05 9.9988782e-01 8.6856055e-08 1.8382856e-08\n",
      "  1.4205347e-10 1.2125619e-05]]\n",
      "Softmax probabilities: [[0.11470404 0.11471549 0.3117629  0.11470404 0.11470404 0.11470404\n",
      "  0.11470543]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Raw model output: [[7.5540449e-08 2.0177505e-04 9.9979025e-01 5.7293029e-08 2.5896595e-08\n",
      "  1.6745041e-10 7.9094398e-06]]\n",
      "Softmax probabilities: [[0.11470625 0.11472938 0.31173846 0.11470625 0.11470623 0.11470623\n",
      "  0.11470715]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Raw model output: [[6.3029375e-08 1.5038531e-04 9.9984097e-01 6.1677198e-08 2.4621341e-08\n",
      "  1.4064062e-10 8.4267122e-06]]\n",
      "Softmax probabilities: [[0.1147051  0.11472234 0.31175116 0.1147051  0.11470509 0.11470509\n",
      "  0.11470605]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Raw model output: [[2.9409370e-07 4.3992951e-10 1.4120432e-06 9.0455288e-08 1.7142011e-06\n",
      "  9.9999642e-01 1.4374699e-08]]\n",
      "Softmax probabilities: [[0.11470162 0.11470158 0.11470175 0.11470159 0.11470178 0.31179008\n",
      "  0.11470158]]\n",
      "Predicted index: 5\n",
      "Predicted gesture: -0.1881687492132187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Raw model output: [[1.1731526e-07 1.8111534e-10 8.1394410e-07 3.3249716e-08 1.3208620e-06\n",
      "  9.9999774e-01 7.1094761e-09]]\n",
      "Softmax probabilities: [[0.11470156 0.11470155 0.11470164 0.11470156 0.1147017  0.3117904\n",
      "  0.11470155]]\n",
      "Predicted index: 5\n",
      "Predicted gesture: -0.1881687492132187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Raw model output: [[6.3602336e-08 2.3807628e-10 6.0771873e-07 2.1054506e-08 3.0072656e-06\n",
      "  9.9999630e-01 1.0961191e-08]]\n",
      "Softmax probabilities: [[0.11470159 0.11470158 0.11470165 0.11470158 0.11470193 0.31179005\n",
      "  0.11470158]]\n",
      "Predicted index: 5\n",
      "Predicted gesture: -0.1881687492132187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Raw model output: [[4.0156063e-08 1.7616701e-10 5.1247480e-07 1.7062076e-08 2.9633800e-06\n",
      "  9.9999642e-01 1.0802067e-08]]\n",
      "Softmax probabilities: [[0.11470159 0.11470158 0.11470164 0.11470158 0.11470193 0.31179008\n",
      "  0.11470158]]\n",
      "Predicted index: 5\n",
      "Predicted gesture: -0.1881687492132187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Raw model output: [[7.3248742e-08 4.2999529e-10 6.7913982e-07 2.0474928e-08 4.4495750e-06\n",
      "  9.9999475e-01 1.7921332e-08]]\n",
      "Softmax probabilities: [[0.11470162 0.11470162 0.1147017  0.11470162 0.11470214 0.31178966\n",
      "  0.11470162]]\n",
      "Predicted index: 5\n",
      "Predicted gesture: -0.1881687492132187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Raw model output: [[6.2541574e-08 3.4416520e-10 6.1386481e-07 2.0355539e-08 4.6194405e-06\n",
      "  9.9999464e-01 1.4971977e-08]]\n",
      "Softmax probabilities: [[0.11470163 0.11470162 0.11470169 0.11470162 0.11470215 0.31178963\n",
      "  0.11470162]]\n",
      "Predicted index: 5\n",
      "Predicted gesture: -0.1881687492132187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Raw model output: [[5.65747484e-08 2.83307433e-10 5.44976785e-07 1.86976248e-08\n",
      "  4.20835386e-06 9.99995232e-01 1.23170985e-08]]\n",
      "Softmax probabilities: [[0.11470162 0.11470161 0.11470167 0.11470161 0.11470209 0.31178978\n",
      "  0.11470161]]\n",
      "Predicted index: 5\n",
      "Predicted gesture: -0.1881687492132187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Raw model output: [[1.08492245e-07 3.31519090e-10 6.17282240e-07 2.17079723e-08\n",
      "  3.47117748e-06 9.99995828e-01 9.68667191e-09]]\n",
      "Softmax probabilities: [[0.11470161 0.11470159 0.11470167 0.11470159 0.11470199 0.31178993\n",
      "  0.11470159]]\n",
      "Predicted index: 5\n",
      "Predicted gesture: -0.1881687492132187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Raw model output: [[2.8538234e-05 3.5328274e-05 1.5792010e-03 2.0979796e-05 9.8477155e-01\n",
      "  9.2123500e-09 1.3564422e-02]]\n",
      "Softmax probabilities: [[0.11504469 0.11504547 0.11522323 0.11504382 0.30798885 0.1150414\n",
      "  0.1166125 ]]\n",
      "Predicted index: 4\n",
      "Predicted gesture: -0.1900433152914047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Raw model output: [[5.3080189e-06 4.9866608e-06 2.7072936e-04 1.0341296e-05 9.9705732e-01\n",
      "  2.5964682e-09 2.6512765e-03]]\n",
      "Softmax probabilities: [[0.11476848 0.11476845 0.11479895 0.11476905 0.3110547  0.11476787\n",
      "  0.11507256]]\n",
      "Predicted index: 4\n",
      "Predicted gesture: -0.1900433152914047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Raw model output: [[3.0783173e-08 4.0742055e-08 1.3301736e-05 1.0137311e-06 9.9990213e-01\n",
      "  8.4285266e-11 8.3509345e-05]]\n",
      "Softmax probabilities: [[0.11470372 0.11470372 0.11470523 0.11470383 0.31176648 0.11470371\n",
      "  0.11471329]]\n",
      "Predicted index: 4\n",
      "Predicted gesture: -0.1900433152914047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Raw model output: [[9.1401319e-08 8.1829789e-08 1.9677742e-05 1.5101647e-06 9.9988163e-01\n",
      "  1.5794968e-10 9.7058350e-05]]\n",
      "Softmax probabilities: [[0.1147042  0.1147042  0.11470645 0.11470436 0.31176138 0.11470419\n",
      "  0.11471532]]\n",
      "Predicted index: 4\n",
      "Predicted gesture: -0.1900433152914047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Raw model output: [[6.2714059e-07 5.9779768e-07 4.2980908e-05 5.0804520e-06 9.9952495e-01\n",
      "  5.9652117e-10 4.2581730e-04]]\n",
      "Softmax probabilities: [[0.1147123  0.1147123  0.11471716 0.1147128  0.31167203 0.11471222\n",
      "  0.11476108]]\n",
      "Predicted index: 4\n",
      "Predicted gesture: -0.1900433152914047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Raw model output: [[8.8539286e-07 1.0855387e-06 4.6366262e-05 4.9875293e-06 9.9944752e-01\n",
      "  7.6355516e-10 4.9919594e-04]]\n",
      "Softmax probabilities: [[0.11471409 0.11471412 0.1147193  0.11471456 0.3116527  0.11471398\n",
      "  0.11477126]]\n",
      "Predicted index: 4\n",
      "Predicted gesture: -0.1900433152914047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Raw model output: [[6.7667105e-07 9.5314772e-07 2.3082352e-05 5.0229874e-06 9.9960798e-01\n",
      "  5.5325189e-10 3.6227854e-04]]\n",
      "Softmax probabilities: [[0.11471044 0.11471047 0.11471301 0.11471093 0.31169283 0.11471036\n",
      "  0.11475192]]\n",
      "Predicted index: 4\n",
      "Predicted gesture: -0.1900433152914047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Raw model output: [[3.1113689e-07 3.6690645e-07 1.4558277e-05 3.1676448e-06 9.9979705e-01\n",
      "  3.0687292e-10 1.8453573e-04]]\n",
      "Softmax probabilities: [[0.11470613 0.11470614 0.11470776 0.11470646 0.3117402  0.11470609\n",
      "  0.11472727]]\n",
      "Predicted index: 4\n",
      "Predicted gesture: -0.1900433152914047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Raw model output: [[1.2851940e-06 1.1962258e-06 4.0311355e-05 6.2843651e-06 9.9947554e-01\n",
      "  9.8062192e-10 4.7541159e-04]]\n",
      "Softmax probabilities: [[0.1147135  0.11471349 0.11471798 0.11471407 0.3116597  0.11471335\n",
      "  0.11476789]]\n",
      "Predicted index: 4\n",
      "Predicted gesture: -0.1900433152914047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Raw model output: [[1.0378253e-06 9.4962854e-07 3.3900211e-05 5.9723752e-06 9.9955398e-01\n",
      "  8.7535662e-10 4.0407278e-04]]\n",
      "Softmax probabilities: [[0.11471169 0.11471169 0.11471546 0.11471226 0.31167933 0.11471158\n",
      "  0.11475795]]\n",
      "Predicted index: 4\n",
      "Predicted gesture: -0.1900433152914047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Raw model output: [[1.0752658e-06 9.7251461e-07 3.4263921e-05 6.1943938e-06 9.9960357e-01\n",
      "  8.8763680e-10 3.5396600e-04]]\n",
      "Softmax probabilities: [[0.11471058 0.11471056 0.11471439 0.11471117 0.31169173 0.11471045\n",
      "  0.11475106]]\n",
      "Predicted index: 4\n",
      "Predicted gesture: -0.1900433152914047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Raw model output: [[2.7114670e-06 1.8881314e-06 6.1596751e-05 9.2557266e-06 9.9938512e-01\n",
      "  1.6731527e-09 5.3927768e-04]]\n",
      "Softmax probabilities: [[0.11471571 0.11471562 0.11472246 0.11471646 0.31163707 0.1147154\n",
      "  0.11477727]]\n",
      "Predicted index: 4\n",
      "Predicted gesture: -0.1900433152914047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Raw model output: [[2.9232160e-06 2.2088411e-06 6.5322063e-05 8.2621737e-06 9.9929476e-01\n",
      "  1.6111239e-09 6.2649744e-04]]\n",
      "Softmax probabilities: [[0.11471777 0.11471769 0.11472493 0.11471839 0.31161445 0.11471743\n",
      "  0.11478933]]\n",
      "Predicted index: 4\n",
      "Predicted gesture: -0.1900433152914047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Raw model output: [[3.7627710e-06 2.9494895e-06 7.7269702e-05 8.8236466e-06 9.9905592e-01\n",
      "  1.8414804e-09 8.5122522e-04]]\n",
      "Softmax probabilities: [[0.11472325 0.11472316 0.11473168 0.11472384 0.31155467 0.11472283\n",
      "  0.11482053]]\n",
      "Predicted index: 4\n",
      "Predicted gesture: -0.1900433152914047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Raw model output: [[2.1468129e-06 2.1974213e-06 6.0181341e-05 1.0777146e-05 9.9913728e-01\n",
      "  1.4953797e-09 7.8733341e-04]]\n",
      "Softmax probabilities: [[0.11472124 0.11472125 0.1147279  0.11472224 0.31157506 0.114721\n",
      "  0.11481136]]\n",
      "Predicted index: 4\n",
      "Predicted gesture: -0.1900433152914047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Raw model output: [[3.8470230e-06 4.1645812e-06 7.2989853e-05 1.1615453e-05 9.9876499e-01\n",
      "  2.0809405e-09 1.1424313e-03]]\n",
      "Softmax probabilities: [[0.11472983 0.11472987 0.11473777 0.11473072 0.31148186 0.11472939\n",
      "  0.11486053]]\n",
      "Predicted index: 4\n",
      "Predicted gesture: -0.1900433152914047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Raw model output: [[2.8960123e-06 2.9465089e-06 4.6755591e-05 8.5557513e-06 9.9927586e-01\n",
      "  1.3825038e-09 6.6296454e-04]]\n",
      "Softmax probabilities: [[0.1147182  0.1147182  0.11472322 0.11471885 0.31160972 0.11471786\n",
      "  0.11479394]]\n",
      "Predicted index: 4\n",
      "Predicted gesture: -0.1900433152914047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Raw model output: [[4.38594952e-06 4.14570786e-06 8.36613617e-05 1.05638965e-05\n",
      "  9.99008119e-01 1.80599002e-09 8.89057817e-04]]\n",
      "Softmax probabilities: [[0.11472441 0.11472438 0.11473351 0.11472512 0.31154272 0.11472391\n",
      "  0.11482595]]\n",
      "Predicted index: 4\n",
      "Predicted gesture: -0.1900433152914047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Raw model output: [[1.2539835e-05 8.8844627e-06 1.4381579e-04 1.2754399e-05 9.9848479e-01\n",
      "  3.1122638e-09 1.3372051e-03]]\n",
      "Softmax probabilities: [[0.11473714 0.11473672 0.11475221 0.11473716 0.31141174 0.11473571\n",
      "  0.11488924]]\n",
      "Predicted index: 4\n",
      "Predicted gesture: -0.1900433152914047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Raw model output: [[8.6212249e-06 7.8247895e-06 1.1169582e-04 1.5989093e-05 9.9836689e-01\n",
      "  2.8443683e-09 1.4890220e-03]]\n",
      "Softmax probabilities: [[0.11473936 0.11473927 0.11475119 0.11474021 0.31138226 0.11473837\n",
      "  0.11490935]]\n",
      "Predicted index: 4\n",
      "Predicted gesture: -0.1900433152914047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Raw model output: [[5.9223630e-06 7.2065423e-06 7.6634016e-05 1.4366076e-05 9.9870908e-01\n",
      "  2.4859264e-09 1.1867842e-03]]\n",
      "Softmax probabilities: [[0.11473133 0.11473148 0.11473946 0.1147323  0.3114679  0.11473066\n",
      "  0.1148669 ]]\n",
      "Predicted index: 4\n",
      "Predicted gesture: -0.1900433152914047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Raw model output: [[1.6757878e-06 2.6556179e-06 3.8714275e-05 7.0867818e-06 9.9934369e-01\n",
      "  1.0508501e-09 6.0618488e-04]]\n",
      "Softmax probabilities: [[0.11471651 0.11471664 0.11472077 0.11471714 0.3116267  0.11471634\n",
      "  0.11478589]]\n",
      "Predicted index: 4\n",
      "Predicted gesture: -0.1900433152914047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Raw model output: [[7.3060875e-07 6.8190993e-06 5.4691586e-04 6.0994327e-05 6.6305012e-01\n",
      "  3.4779323e-08 3.3633444e-01]]\n",
      "Softmax probabilities: [[0.11988797 0.1198887  0.11995348 0.11989519 0.23266675 0.1198879\n",
      "  0.16781992]]\n",
      "Predicted index: 4\n",
      "Predicted gesture: -0.1900433152914047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Raw model output: [[5.9830136e-08 3.0035940e-06 2.7622830e-04 5.9271839e-05 6.8097061e-01\n",
      "  2.3865825e-08 3.1869087e-01]]\n",
      "Softmax probabilities: [[0.11973955 0.1197399  0.11977263 0.11974664 0.23658074 0.11973955\n",
      "  0.16468093]]\n",
      "Predicted index: 4\n",
      "Predicted gesture: -0.1900433152914047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Raw model output: [[1.3092196e-07 6.2723293e-06 5.8660068e-04 5.1139905e-05 2.7512667e-01\n",
      "  3.0842720e-08 7.2422922e-01]]\n",
      "Softmax probabilities: [[0.11932489 0.11932563 0.1193949  0.11933099 0.15711476 0.11932489\n",
      "  0.24618396]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Raw model output: [[7.5109028e-08 4.2961692e-06 3.1471869e-04 9.3812327e-05 4.9051264e-01\n",
      "  2.9745529e-08 5.0907445e-01]]\n",
      "Softmax probabilities: [[0.1205209  0.12052141 0.12055882 0.12053219 0.1968291  0.12052089\n",
      "  0.20051672]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Raw model output: [[3.1917564e-09 4.9221461e-07 5.1589860e-03 3.8155711e-08 2.0862941e-02\n",
      "  9.2492007e-11 9.7397751e-01]]\n",
      "Softmax probabilities: [[0.1152776  0.11527766 0.11587385 0.11527761 0.11770789 0.1152776\n",
      "  0.30530784]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Raw model output: [[2.6307059e-09 3.6162143e-07 2.1391020e-03 3.6283165e-08 2.9703947e-03\n",
      "  6.4064663e-11 9.9489021e-01]]\n",
      "Softmax probabilities: [[0.11481657 0.11481661 0.11506244 0.11481658 0.11515813 0.11481657\n",
      "  0.31051305]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Raw model output: [[5.0316307e-10 2.5287451e-07 1.4593785e-03 1.6900481e-08 5.4060845e-03\n",
      "  2.0360429e-11 9.9313426e-01]]\n",
      "Softmax probabilities: [[0.11485589 0.11485591 0.11502363 0.11485589 0.11547849 0.11485589\n",
      "  0.31007442]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Raw model output: [[3.1019262e-10 2.2954802e-07 1.6411989e-03 9.8702673e-09 2.3126060e-03\n",
      "  1.2450183e-11 9.9604589e-01]]\n",
      "Softmax probabilities: [[0.11479063 0.11479066 0.11497919 0.11479063 0.11505641 0.11479063\n",
      "  0.3108019 ]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Raw model output: [[9.6139061e-09 1.6135718e-07 9.9862289e-01 1.3111408e-08 1.5742339e-04\n",
      "  8.0092833e-12 1.2196675e-03]]\n",
      "Softmax probabilities: [[0.1147326  0.11473262 0.3114463  0.1147326  0.11475066 0.1147326\n",
      "  0.11487261]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Raw model output: [[3.4003417e-08 5.0917109e-08 9.9996877e-01 1.8946908e-09 1.2964278e-05\n",
      "  2.5057393e-12 1.8279738e-05]]\n",
      "Softmax probabilities: [[0.11470222 0.11470222 0.31178316 0.1147022  0.1147037  0.1147022\n",
      "  0.1147043 ]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Raw model output: [[5.1038649e-09 6.2697225e-09 9.9999762e-01 3.8613384e-09 1.9476815e-06\n",
      "  6.1364238e-13 4.8866343e-07]]\n",
      "Softmax probabilities: [[0.11470155 0.11470155 0.31179038 0.11470155 0.11470179 0.11470155\n",
      "  0.11470161]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Raw model output: [[1.4603216e-09 2.4713032e-09 9.9999917e-01 3.5209280e-09 6.5682809e-07\n",
      "  2.5723960e-13 9.4857356e-08]]\n",
      "Softmax probabilities: [[0.11470152 0.11470152 0.31179076 0.11470152 0.11470159 0.11470152\n",
      "  0.11470154]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Raw model output: [[6.5900663e-10 8.9049557e-10 9.9999988e-01 6.4579092e-10 7.5052000e-08\n",
      "  3.2284657e-14 4.5651998e-09]]\n",
      "Softmax probabilities: [[0.1147015  0.1147015  0.31179094 0.1147015  0.11470151 0.1147015\n",
      "  0.1147015 ]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Raw model output: [[1.74343072e-07 1.08764084e-07 9.99999642e-01 1.65367664e-09\n",
      "  1.04242879e-07 8.04861061e-13 2.60863064e-08]]\n",
      "Softmax probabilities: [[0.11470152 0.11470152 0.31179088 0.1147015  0.11470152 0.1147015\n",
      "  0.1147015 ]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Raw model output: [[1.0503758e-05 3.3965364e-06 9.9996471e-01 1.1966593e-08 2.1067031e-05\n",
      "  2.1117517e-11 1.9884401e-07]]\n",
      "Softmax probabilities: [[0.11470351 0.1147027  0.31178218 0.11470231 0.11470473 0.11470231\n",
      "  0.11470234]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Raw model output: [[4.4489174e-05 2.6421854e-05 9.9931252e-01 5.4892926e-08 6.1531342e-04\n",
      "  2.1686619e-10 1.1720161e-06]]\n",
      "Softmax probabilities: [[0.11472212 0.11472005 0.31161886 0.11471703 0.11478763 0.11471702\n",
      "  0.11471716]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Raw model output: [[4.4909142e-05 2.4992598e-05 9.9909508e-01 6.0809739e-08 8.3365251e-04\n",
      "  2.5830335e-10 1.3366116e-06]]\n",
      "Softmax probabilities: [[0.11472709 0.11472481 0.31156448 0.11472195 0.11481762 0.11472194\n",
      "  0.11472209]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Raw model output: [[2.4139862e-04 6.2120045e-05 6.0050254e-04 1.7635541e-05 4.0009414e-07\n",
      "  1.3881424e-07 9.9907780e-01]]\n",
      "Softmax probabilities: [[0.11475004 0.11472946 0.11479125 0.11472436 0.11472239 0.11472235\n",
      "  0.31156015]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Raw model output: [[2.2426078e-03 1.0381944e-04 9.2041632e-04 2.5992014e-05 1.8949073e-07\n",
      "  3.4031720e-07 9.9670666e-01]]\n",
      "Softmax probabilities: [[0.11503347 0.11478771 0.11488147 0.11477877 0.11477581 0.11477582\n",
      "  0.3109671 ]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n"
     ]
    }
   ],
   "source": [
    "#Script for Static guesture prediction\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from tensorflow import keras  \n",
    "from collections import deque\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load trained model and label encoder\n",
    "model = keras.models.load_model(\"gesture_model.keras\")\n",
    "label_encoder = LabelEncoder()\n",
    "label_classes = np.load(\"label_classes.npy\", allow_pickle=True)\n",
    "label_encoder.classes_ = label_classes  # Assign loaded labels\n",
    "\n",
    "# Debug: Print classes to verify correct loading\n",
    "print(\"Loaded gesture classes:\", label_classes)\n",
    "\n",
    "# Initialize Mediapipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.5)\n",
    "\n",
    "# Store last 30 frames of landmarks\n",
    "landmark_history = deque(maxlen=30)\n",
    "\n",
    "# Function to detect if hand is static\n",
    "def isStatic(landmark_history, threshold=0.1):  # Lowered threshold for better sensitivity\n",
    "    \"\"\"Check if hand is static by comparing last two frames.\"\"\"\n",
    "    if len(landmark_history) < 2:\n",
    "        return True  # Assume static if not enough frames\n",
    "\n",
    "    # Compute Euclidean distance between last two frames\n",
    "    distance = np.linalg.norm(np.array(landmark_history[-1]) - np.array(landmark_history[-2]))\n",
    "\n",
    "    return distance < threshold  # If movement is below threshold, it's static\n",
    "\n",
    "# Start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(rgb_frame)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Extract landmarks (21 points, each with x, y, z)\n",
    "            landmarks = []\n",
    "            for lm in hand_landmarks.landmark:\n",
    "                landmarks.extend([lm.x, lm.y, lm.z])\n",
    "\n",
    "            # Store in history\n",
    "            landmark_history.append(landmarks)\n",
    "\n",
    "            # Check if static or dynamic\n",
    "            if isStatic(landmark_history):\n",
    "                if len(landmarks) == 63:  # Ensure correct shape\n",
    "                    landmarks_array = np.array(landmarks).reshape(1, -1).astype(np.float32)\n",
    "\n",
    "                    # Make prediction\n",
    "                    prediction = model.predict(landmarks_array)\n",
    "                    print(\"Raw model output:\", prediction)  # Print raw model output\n",
    "\n",
    "                    # Convert logits to probabilities (only if your model doesn't already output probabilities)\n",
    "                    if prediction.shape[1] > 1:  # Check if multi-class\n",
    "                        prediction_prob = keras.activations.softmax(keras.backend.variable(prediction)).numpy()\n",
    "                    else:\n",
    "                        prediction_prob = prediction  # If already probabilities\n",
    "\n",
    "                    print(\"Softmax probabilities:\", prediction_prob)  # Debug print\n",
    "\n",
    "                    # Get predicted class index\n",
    "                    predicted_index = np.argmax(prediction_prob)\n",
    "                    print(\"Predicted index:\", predicted_index)  # Debug print\n",
    "\n",
    "                    # Ensure the index is valid\n",
    "                    if 0 <= predicted_index < len(label_encoder.classes_):\n",
    "                        gesture = label_encoder.inverse_transform([predicted_index])[0]\n",
    "                    else:\n",
    "                        gesture = \"Unknown\"\n",
    "\n",
    "                    print(\"Predicted gesture:\", gesture)  # Debug print\n",
    "\n",
    "\n",
    "                    # Ensure valid index\n",
    "                    if 0 <= predicted_index < len(label_encoder.classes_):\n",
    "                        if(predicted_index==0):\n",
    "                            gesture=\"fist\"\n",
    "                        if(predicted_index==1):\n",
    "                            gesture=\"fuck off\"\n",
    "                        if(predicted_index==2):\n",
    "                            gesture=\"open palm\" \n",
    "                        if(predicted_index==3):\n",
    "                            gesture=\"spiderman\"\n",
    "                        if(predicted_index==5):\n",
    "                            gesture=\"thumbs upp\"\n",
    "                        if(predicted_index==6):\n",
    "                            gesture=\"thumbs down\"\n",
    "                        if(predicted_index==6):\n",
    "                            gesture=\"victory\"  \n",
    "                        #gesture = label_encoder.inverse_transform([predicted_index])[0]\n",
    "                    else:\n",
    "                        gesture = \"Unknown\"\n",
    "\n",
    "                    # Display static gesture\n",
    "                    cv2.putText(frame, \"Static\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, f\"Gesture: {gesture}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                else:\n",
    "                    cv2.putText(frame, \"Error: Landmark Shape\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            else:\n",
    "                cv2.putText(frame, \"Dynamic\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Hand Gesture Recognition\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to exit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'q' to stop recording.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Convert frame to RGB\u001b[39;00m\n\u001b[0;32m     43\u001b[0m rgb_frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m---> 44\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mhands\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m frame_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(gesture_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mframe_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     47\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(frame_path, frame)  \u001b[38;5;66;03m# Save the RGB frame\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\AYUSH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mediapipe\\python\\solutions\\hands.py:153\u001b[0m, in \u001b[0;36mHands.process\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[0;32m    133\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the hand landmarks and handedness of each detected hand.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;124;03m         right hand) of the detected hand.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\AYUSH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mediapipe\\python\\solution_base.py:340\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    334\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[0;32m    336\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[0;32m    337\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[0;32m    338\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Mediapipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.5)\n",
    "\n",
    "# Set storage paths\n",
    "DATASET_PATH = \"dataset_dymnamic\"\n",
    "CSV_FILE = \"hand_landmarks_dynamic.csv\"\n",
    "\n",
    "# Create dataset folder if not exists\n",
    "os.makedirs(DATASET_PATH, exist_ok=True)\n",
    "\n",
    "# Initialize CSV storage\n",
    "columns = [\"frame_number\", \"gesture\"] + [f\"{axis}{i}\" for i in range(21) for axis in [\"x\", \"y\", \"z\"]]\n",
    "if not os.path.exists(CSV_FILE):\n",
    "    pd.DataFrame(columns=columns).to_csv(CSV_FILE, index=False)\n",
    "\n",
    "# Get gesture name from user\n",
    "s=\"Bye\"\n",
    "gesture_name = s.strip().lower()\n",
    "gesture_folder = os.path.join(DATASET_PATH, gesture_name)\n",
    "os.makedirs(gesture_folder, exist_ok=True)\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "frame_count = 0\n",
    "landmark_data = []\n",
    "\n",
    "print(\"Press 'q' to stop recording.\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(rgb_frame)\n",
    "\n",
    "    frame_path = os.path.join(gesture_folder, f\"{frame_count}.jpg\")\n",
    "    cv2.imwrite(frame_path, frame)  # Save the RGB frame\n",
    "\n",
    "    # Process hand landmarks\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Extract 21 hand landmarks\n",
    "            landmarks = []\n",
    "            for lm in hand_landmarks.landmark:\n",
    "                landmarks.extend([lm.x, lm.y, lm.z])\n",
    "\n",
    "            # Save landmarks to list\n",
    "            landmark_data.append([frame_count, gesture_name] + landmarks)\n",
    "\n",
    "    cv2.imshow(\"Recording Gesture\", frame)\n",
    "    frame_count += 1\n",
    "\n",
    "    # Stop recording\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Append landmark data to CSV\n",
    "df = pd.DataFrame(landmark_data, columns=columns)\n",
    "df.to_csv(CSV_FILE, mode='a', header=False, index=False)\n",
    "\n",
    "print(f\"✅ Gesture '{gesture_name}' recorded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the guesture name and csv file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording gesture: M Chuda...\n",
      "✅ Recording Complete!\n",
      "Batching frames into 100 samples with mirrored versions...\n",
      "✅ Batching Complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "\n",
    "# Configuration\n",
    "GESTURE_NAME = \"M Chuda\"  # Change this for different gestures\n",
    "SAVE_DIR = \"dataset\"\n",
    "FRAME_LIMIT = 3000  # Total frames to capture\n",
    "BATCH_SIZE = 30  # Frames per sample\n",
    "SAMPLES = 100  # Total gesture samples\n",
    "\n",
    "# Create directories\n",
    "rgb_path = os.path.join(SAVE_DIR, GESTURE_NAME, \"RGB_Frames\")\n",
    "os.makedirs(rgb_path, exist_ok=True)\n",
    "\n",
    "# Initialize Mediapipe\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.5)\n",
    "\n",
    "# Start Video Capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "frames = []\n",
    "landmarks_list = []\n",
    "\n",
    "print(f\"Recording gesture: {GESTURE_NAME}...\")\n",
    "\n",
    "frame_count = 0\n",
    "while frame_count < FRAME_LIMIT:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Process frame\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(rgb_frame)\n",
    "\n",
    "    # Save RGB frame\n",
    "    frame_filename = os.path.join(rgb_path, f\"frame_{frame_count}.jpg\")\n",
    "    cv2.imwrite(frame_filename, frame)\n",
    "\n",
    "    # Extract landmarks\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            lm_list = []\n",
    "            for lm in hand_landmarks.landmark:\n",
    "                lm_list.extend([lm.x, lm.y, lm.z])\n",
    "            landmarks_list.append([frame_count] + lm_list)  # Add frame index\n",
    "    else:\n",
    "        landmarks_list.append([frame_count] + [None] * 63)  # Empty if no hand detected\n",
    "\n",
    "    # Display recording progress\n",
    "    cv2.putText(frame, f\"Recording {frame_count}/{FRAME_LIMIT}\", (10, 30), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Recording\", frame)\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to quit early\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save all landmarks in one CSV file\n",
    "csv_path = os.path.join(SAVE_DIR, GESTURE_NAME, \"landmarks_4.csv\")\n",
    "columns = [\"Frame\"] + [f\"LM_{i}\" for i in range(63)]  # Column names\n",
    "landmarks_df = pd.DataFrame(landmarks_list, columns=columns)\n",
    "landmarks_df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(\"✅ Recording Complete!\")\n",
    "\n",
    "# --- Batching into 100 samples ---\n",
    "print(\"Batching frames into 100 samples with mirrored versions...\")\n",
    "\n",
    "# Ensure correct number of frames\n",
    "if len(landmarks_list) >= FRAME_LIMIT:\n",
    "    for sample_idx in range(SAMPLES):\n",
    "        start_idx = sample_idx * BATCH_SIZE\n",
    "        end_idx = start_idx + BATCH_SIZE\n",
    "\n",
    "        if end_idx <= FRAME_LIMIT:\n",
    "            batch_rgb_dir = os.path.join(rgb_path, f\"sample_{sample_idx}\")\n",
    "            os.makedirs(batch_rgb_dir, exist_ok=True)\n",
    "\n",
    "            # Save RGB frames for this batch\n",
    "            for i in range(start_idx, end_idx):\n",
    "                original_path = os.path.join(rgb_path, f\"frame_{i}.jpg\")\n",
    "                mirrored_path = os.path.join(batch_rgb_dir, f\"mirrored_{i % BATCH_SIZE}.jpg\")\n",
    "                new_path = os.path.join(batch_rgb_dir, f\"frame_{i % BATCH_SIZE}.jpg\")\n",
    "\n",
    "                # Move original\n",
    "                os.rename(original_path, new_path)\n",
    "\n",
    "                # Create and save mirrored image\n",
    "                img = cv2.imread(new_path)\n",
    "                mirrored_img = cv2.flip(img, 1)  # Horizontal flip\n",
    "                cv2.imwrite(mirrored_path, mirrored_img)\n",
    "\n",
    "print(\"✅ Batching Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape after slicing: (320, 30, 63)\n",
      "X_test shape after slicing: (80, 30, 63)\n",
      "y_train shape: (320, 4)\n",
      "y_test shape: (80, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load data first\n",
    "X_train1 = np.load(\"X_train.npy\")\n",
    "X_test1 = np.load(\"X_test.npy\")\n",
    "y_train1 = np.load(\"y_train.npy\")\n",
    "y_test1 = np.load(\"y_test.npy\")\n",
    "\n",
    "# Keep only the first 63 features (21 landmarks * 3 coordinates)\n",
    "X_train1 = X_train[:, :, :63]\n",
    "X_test1 = X_test1[:, :, :63]\n",
    "\n",
    "# Print shapes for verification\n",
    "print(f\"X_train shape after slicing: {X_train1.shape}\")  # Expected: (num_samples, 30, 63)\n",
    "print(f\"X_test shape after slicing: {X_test1.shape}\")\n",
    "print(f\"y_train shape: {y_train1.shape}\")\n",
    "print(f\"y_test shape: {y_test1.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 30, 63)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 9.00000000e+01,  5.31555951e-01,  9.12091613e-01, -2.50735297e-07,\n",
       "        4.76505399e-01,  8.43463778e-01, -1.33538423e-02,  4.52662855e-01,\n",
       "        7.38568306e-01, -2.93067899e-02,  4.66599166e-01,  6.41250968e-01,\n",
       "       -4.09852825e-02,  5.06354570e-01,  5.97764015e-01, -4.94472235e-02,\n",
       "        4.82463092e-01,  7.78885663e-01, -6.65162951e-02,  5.07402778e-01,\n",
       "        6.20306313e-01, -9.62230638e-02,  4.98349488e-01,  6.11827910e-01,\n",
       "       -1.00337245e-01,  4.90918249e-01,  6.39743865e-01, -9.57352221e-02,\n",
       "        5.41257262e-01,  7.91390777e-01, -6.67643920e-02,  5.50480008e-01,\n",
       "        6.20874524e-01, -9.30399373e-02,  5.32759428e-01,  6.38566732e-01,\n",
       "       -8.64594132e-02,  5.27896464e-01,  6.83886051e-01, -7.50860572e-02,\n",
       "        5.93722522e-01,  7.95771897e-01, -6.50351122e-02,  5.88451743e-01,\n",
       "        6.42645299e-01, -8.36455300e-02,  5.67662776e-01,  6.69328392e-01,\n",
       "       -6.63551837e-02,  5.63294172e-01,  7.13357210e-01, -4.86729443e-02,\n",
       "        6.36539519e-01,  7.94844091e-01, -6.32061288e-02,  6.22234523e-01,\n",
       "        6.85445786e-01, -7.11501613e-02,  6.03756785e-01,  7.04120278e-01,\n",
       "       -5.78071102e-02,  6.05013311e-01,  7.38803804e-01])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "X_train[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected gestures: ['I am Inavatable', 'M Chuda', 'Time reversal', 'wave']\n",
      "✅ Total valid samples collected: 400\n",
      "✅ Preprocessing completed successfully! Ready for 3D CNN training.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Dataset path\n",
    "DATASET_PATH = \"dataset\"\n",
    "NUM_FRAMES = 30  \n",
    "GESTURE_CLASSES = sorted(os.listdir(DATASET_PATH))  # List gesture folders\n",
    "\n",
    "# Initialize lists\n",
    "X_landmarks = []\n",
    "y = []\n",
    "\n",
    "print(\"Detected gestures:\", GESTURE_CLASSES)\n",
    "\n",
    "# Process each gesture\n",
    "for label, gesture in enumerate(GESTURE_CLASSES):\n",
    "    gesture_folder = os.path.join(DATASET_PATH, gesture)\n",
    "    \n",
    "    # Detect landmark CSV dynamically\n",
    "    landmark_csv_files = glob.glob(os.path.join(gesture_folder, \"landmarks*.csv\"))\n",
    "    \n",
    "    if not landmark_csv_files:\n",
    "        print(f\"⚠️ Warning: No landmarks CSV found for {gesture}, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    landmark_csv_path = landmark_csv_files[0]\n",
    "    df_landmarks = pd.read_csv(landmark_csv_path)\n",
    "\n",
    "    # Reshape landmarks into (100 samples, 50 frames, landmark features)\n",
    "    num_samples = len(df_landmarks) // NUM_FRAMES\n",
    "\n",
    "    if num_samples < 100:\n",
    "        print(f\"⚠️ Warning: {gesture} has only {num_samples} samples (expected 100), skipping...\")\n",
    "        continue\n",
    "\n",
    "    landmarks = df_landmarks.values.reshape(num_samples, NUM_FRAMES, -1)\n",
    "\n",
    "    # Append data\n",
    "    X_landmarks.extend(landmarks)\n",
    "    y.extend([label] * num_samples)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_landmarks = np.array(X_landmarks)\n",
    "y = to_categorical(np.array(y), num_classes=len(GESTURE_CLASSES))\n",
    "\n",
    "# Debugging print\n",
    "print(f\"✅ Total valid samples collected: {X_landmarks.shape[0]}\")\n",
    "\n",
    "# Proceed if data is available\n",
    "if X_landmarks.shape[0] == 0:\n",
    "    raise ValueError(\"❌ No valid samples found. Check dataset structure!\")\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_landmarks, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save preprocessed data\n",
    "np.save(\"X_train.npy\", X_train)\n",
    "np.save(\"X_test.npy\", X_test)\n",
    "np.save(\"y_train.npy\", y_train)\n",
    "np.save(\"y_test.npy\", y_test)\n",
    "\n",
    "print(\"✅ Preprocessing completed successfully! Ready for 3D CNN training.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM Model for Dynamic Guesture Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AYUSH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.2601 - loss: 1.4058\n",
      "Epoch 2/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2667 - loss: 1.3813\n",
      "Epoch 3/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2904 - loss: 1.3891\n",
      "Epoch 4/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2613 - loss: 1.3926\n",
      "Epoch 5/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2511 - loss: 1.3785\n",
      "Epoch 6/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4540 - loss: 1.3244\n",
      "Epoch 7/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2505 - loss: 1.3889\n",
      "Epoch 8/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2567 - loss: 1.4032\n",
      "Epoch 9/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2399 - loss: 1.3811\n",
      "Epoch 10/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2376 - loss: 1.3679\n",
      "Epoch 11/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3867 - loss: 1.2541\n",
      "Epoch 12/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4141 - loss: 1.1833\n",
      "Epoch 13/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2861 - loss: 1.3548\n",
      "Epoch 14/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3858 - loss: 1.2404\n",
      "Epoch 15/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4733 - loss: 1.1315\n",
      "Epoch 16/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3467 - loss: 1.3258\n",
      "Epoch 17/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4509 - loss: 1.1587\n",
      "Epoch 18/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5380 - loss: 1.0274\n",
      "Epoch 19/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4145 - loss: 1.2284\n",
      "Epoch 20/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4854 - loss: 1.1021\n",
      "Epoch 21/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.4796 - loss: 0.9837\n",
      "Epoch 22/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 0.5412 - loss: 0.9314\n",
      "Epoch 23/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 0.5634 - loss: 0.8725\n",
      "Epoch 24/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 0.4467 - loss: 1.0246\n",
      "Epoch 25/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.5821 - loss: 0.8624\n",
      "Epoch 26/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 0.5244 - loss: 0.9458\n",
      "Epoch 27/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 0.5807 - loss: 0.8838\n",
      "Epoch 28/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 0.4615 - loss: 1.2747\n",
      "Epoch 29/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 0.5451 - loss: 1.0281\n",
      "Epoch 30/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - accuracy: 0.6484 - loss: 0.8908\n",
      "Epoch 31/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - accuracy: 0.6377 - loss: 0.8347\n",
      "Epoch 32/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - accuracy: 0.6272 - loss: 0.7949\n",
      "Epoch 33/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 0.5866 - loss: 0.9113\n",
      "Epoch 34/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5365 - loss: 0.9769\n",
      "Epoch 35/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6208 - loss: 0.7979\n",
      "Epoch 36/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6616 - loss: 0.7313\n",
      "Epoch 37/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6062 - loss: 0.8506\n",
      "Epoch 38/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6286 - loss: 0.7763\n",
      "Epoch 39/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5769 - loss: 0.8046\n",
      "Epoch 40/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6452 - loss: 0.7852\n",
      "Epoch 41/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6525 - loss: 0.7628\n",
      "Epoch 42/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5515 - loss: 0.9354\n",
      "Epoch 43/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5964 - loss: 0.8980\n",
      "Epoch 44/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5967 - loss: 0.9512\n",
      "Epoch 45/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6539 - loss: 0.7740\n",
      "Epoch 46/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6853 - loss: 0.6897\n",
      "Epoch 47/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6472 - loss: 0.7666\n",
      "Epoch 48/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6618 - loss: 0.7308\n",
      "Epoch 49/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6840 - loss: 0.7450\n",
      "Epoch 50/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6739 - loss: 0.6975\n",
      "Epoch 51/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6964 - loss: 0.6059\n",
      "Epoch 52/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7321 - loss: 0.7511\n",
      "Epoch 53/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5844 - loss: 0.8283\n",
      "Epoch 54/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6932 - loss: 0.6999\n",
      "Epoch 55/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6005 - loss: 0.8104\n",
      "Epoch 56/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6753 - loss: 0.6844\n",
      "Epoch 57/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6982 - loss: 0.6215\n",
      "Epoch 58/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5713 - loss: 0.9954\n",
      "Epoch 59/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6315 - loss: 0.8481\n",
      "Epoch 60/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6135 - loss: 0.8249\n",
      "Epoch 61/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6132 - loss: 0.8682\n",
      "Epoch 62/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7232 - loss: 0.6440\n",
      "Epoch 63/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7483 - loss: 0.6376\n",
      "Epoch 64/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7138 - loss: 0.6884\n",
      "Epoch 65/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7396 - loss: 0.6041\n",
      "Epoch 66/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5881 - loss: 0.7135\n",
      "Epoch 67/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6598 - loss: 0.6687\n",
      "Epoch 68/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7398 - loss: 0.5864\n",
      "Epoch 69/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6963 - loss: 0.5968\n",
      "Epoch 70/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7091 - loss: 0.5715\n",
      "Epoch 71/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6899 - loss: 0.6166\n",
      "Epoch 72/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6225 - loss: 0.8068\n",
      "Epoch 73/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7083 - loss: 0.5828\n",
      "Epoch 74/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7651 - loss: 0.5861\n",
      "Epoch 75/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8162 - loss: 0.4779\n",
      "Epoch 76/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7337 - loss: 0.6221\n",
      "Epoch 77/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7389 - loss: 0.5484\n",
      "Epoch 78/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6521 - loss: 0.8251\n",
      "Epoch 79/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7271 - loss: 0.6333\n",
      "Epoch 80/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7813 - loss: 0.5566\n",
      "Epoch 81/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8301 - loss: 0.4630\n",
      "Epoch 82/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7317 - loss: 0.5573\n",
      "Epoch 83/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6978 - loss: 0.6541\n",
      "Epoch 84/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9090 - loss: 0.3556\n",
      "Epoch 85/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8696 - loss: 0.3512\n",
      "Epoch 86/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8453 - loss: 0.3907\n",
      "Epoch 87/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8819 - loss: 0.3495\n",
      "Epoch 88/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8569 - loss: 0.3201\n",
      "Epoch 89/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8141 - loss: 0.4489\n",
      "Epoch 90/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8248 - loss: 0.5006\n",
      "Epoch 91/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8626 - loss: 0.3030\n",
      "Epoch 92/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7698 - loss: 0.4649\n",
      "Epoch 93/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8719 - loss: 0.2884\n",
      "Epoch 94/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7941 - loss: 0.4949\n",
      "Epoch 95/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7253 - loss: 0.7452\n",
      "Epoch 96/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8548 - loss: 0.3545\n",
      "Epoch 97/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8812 - loss: 0.3289\n",
      "Epoch 98/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9056 - loss: 0.2917\n",
      "Epoch 99/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8078 - loss: 0.4123\n",
      "Epoch 100/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6754 - loss: 0.8478\n",
      "Epoch 101/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6833 - loss: 0.8692\n",
      "Epoch 102/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7824 - loss: 0.5773\n",
      "Epoch 103/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8574 - loss: 0.3546\n",
      "Epoch 104/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8533 - loss: 0.3593\n",
      "Epoch 105/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8097 - loss: 0.5050\n",
      "Epoch 106/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8394 - loss: 0.4555\n",
      "Epoch 107/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8225 - loss: 0.5341\n",
      "Epoch 108/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9032 - loss: 0.2793\n",
      "Epoch 109/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9363 - loss: 0.2397\n",
      "Epoch 110/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9090 - loss: 0.2237\n",
      "Epoch 111/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9223 - loss: 0.2497\n",
      "Epoch 112/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9511 - loss: 0.1689\n",
      "Epoch 113/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9292 - loss: 0.1725\n",
      "Epoch 114/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9451 - loss: 0.1716\n",
      "Epoch 115/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9176 - loss: 0.1809\n",
      "Epoch 116/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9109 - loss: 0.1942\n",
      "Epoch 117/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9492 - loss: 0.1561\n",
      "Epoch 118/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9324 - loss: 0.1972\n",
      "Epoch 119/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9499 - loss: 0.1238\n",
      "Epoch 120/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9523 - loss: 0.1422\n",
      "Epoch 121/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9317 - loss: 0.1956\n",
      "Epoch 122/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 0.9178 - loss: 0.2327\n",
      "Epoch 123/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.9332 - loss: 0.1780\n",
      "Epoch 124/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.8980 - loss: 0.3223\n",
      "Epoch 125/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - accuracy: 0.8974 - loss: 0.2564\n",
      "Epoch 126/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.9171 - loss: 0.2061\n",
      "Epoch 127/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - accuracy: 0.9422 - loss: 0.1687\n",
      "Epoch 128/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - accuracy: 0.9561 - loss: 0.1403\n",
      "Epoch 129/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.9358 - loss: 0.1848\n",
      "Epoch 130/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - accuracy: 0.9867 - loss: 0.0907\n",
      "Epoch 131/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.9596 - loss: 0.1076\n",
      "Epoch 132/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.9816 - loss: 0.0926\n",
      "Epoch 133/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.9235 - loss: 0.1903\n",
      "Epoch 134/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 156ms/step - accuracy: 0.9511 - loss: 0.1542\n",
      "Epoch 135/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 161ms/step - accuracy: 0.9755 - loss: 0.0859\n",
      "Epoch 136/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - accuracy: 0.9569 - loss: 0.1176\n",
      "Epoch 137/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9625 - loss: 0.1079\n",
      "Epoch 138/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9628 - loss: 0.1400\n",
      "Epoch 139/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9152 - loss: 0.2741\n",
      "Epoch 140/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9567 - loss: 0.1168\n",
      "Epoch 141/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9804 - loss: 0.0829\n",
      "Epoch 142/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9537 - loss: 0.1241\n",
      "Epoch 143/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9522 - loss: 0.1498\n",
      "Epoch 144/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8969 - loss: 0.2527\n",
      "Epoch 145/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9605 - loss: 0.1366\n",
      "Epoch 146/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9122 - loss: 0.2046\n",
      "Epoch 147/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9534 - loss: 0.1364\n",
      "Epoch 148/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9647 - loss: 0.1176\n",
      "Epoch 149/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9368 - loss: 0.2109\n",
      "Epoch 150/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8094 - loss: 0.5208\n",
      "Epoch 151/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9317 - loss: 0.1674\n",
      "Epoch 152/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9660 - loss: 0.1423\n",
      "Epoch 153/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9784 - loss: 0.0941\n",
      "Epoch 154/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9650 - loss: 0.1037\n",
      "Epoch 155/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9723 - loss: 0.1082\n",
      "Epoch 156/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9696 - loss: 0.1067\n",
      "Epoch 157/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9453 - loss: 0.1476\n",
      "Epoch 158/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9004 - loss: 0.2665\n",
      "Epoch 159/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9257 - loss: 0.2004\n",
      "Epoch 160/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9242 - loss: 0.1809\n",
      "Epoch 161/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9592 - loss: 0.0880\n",
      "Epoch 162/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9766 - loss: 0.0836\n",
      "Epoch 163/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9554 - loss: 0.1325\n",
      "Epoch 164/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9478 - loss: 0.1607\n",
      "Epoch 165/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9402 - loss: 0.1748\n",
      "Epoch 166/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8564 - loss: 0.4639\n",
      "Epoch 167/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9387 - loss: 0.1958\n",
      "Epoch 168/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9470 - loss: 0.1249\n",
      "Epoch 169/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9782 - loss: 0.1080\n",
      "Epoch 170/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9042 - loss: 0.2654\n",
      "Epoch 171/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9135 - loss: 0.2259\n",
      "Epoch 172/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9719 - loss: 0.1115\n",
      "Epoch 173/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9580 - loss: 0.1335\n",
      "Epoch 174/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9495 - loss: 0.1196\n",
      "Epoch 175/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9708 - loss: 0.0879\n",
      "Epoch 176/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9673 - loss: 0.0841\n",
      "Epoch 177/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9796 - loss: 0.0698\n",
      "Epoch 178/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9535 - loss: 0.1269\n",
      "Epoch 179/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9786 - loss: 0.0665\n",
      "Epoch 180/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9787 - loss: 0.0561\n",
      "Epoch 181/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9882 - loss: 0.0702\n",
      "Epoch 182/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9862 - loss: 0.0703\n",
      "Epoch 183/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9757 - loss: 0.0684\n",
      "Epoch 184/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9232 - loss: 0.2199\n",
      "Epoch 185/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8127 - loss: 0.6785\n",
      "Epoch 186/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9523 - loss: 0.1577\n",
      "Epoch 187/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9769 - loss: 0.0905\n",
      "Epoch 188/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9540 - loss: 0.1019\n",
      "Epoch 189/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9413 - loss: 0.1836\n",
      "Epoch 190/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9516 - loss: 0.1127\n",
      "Epoch 191/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9574 - loss: 0.0929\n",
      "Epoch 192/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9143 - loss: 0.2488\n",
      "Epoch 193/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9693 - loss: 0.0856\n",
      "Epoch 194/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9887 - loss: 0.0559\n",
      "Epoch 195/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9782 - loss: 0.0768\n",
      "Epoch 196/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9854 - loss: 0.0447\n",
      "Epoch 197/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9895 - loss: 0.0463\n",
      "Epoch 198/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9957 - loss: 0.0287\n",
      "Epoch 199/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9923 - loss: 0.0406\n",
      "Epoch 200/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9944 - loss: 0.0385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "\n",
    "# Improved LSTM Model\n",
    "model = Sequential([\n",
    "    LSTM(128, return_sequences=True, input_shape=(30, 63)),  # More units\n",
    "    BatchNormalization(),\n",
    "    #Dropout(0.5),\n",
    "\n",
    "    LSTM(64, return_sequences=True),  # Reduce for better generalization\n",
    "    BatchNormalization(),\n",
    "    LSTM(32, return_sequences=False),\n",
    "    #Dropout(0.5),\n",
    "\n",
    "    Dense(32, activation='relu'),\n",
    "    #Dropout(0.3),\n",
    "\n",
    "    Dense(4, activation='softmax')  # Assuming 4 classes\n",
    "])\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train Model\n",
    "model.fit(X_train1, y_train1, epochs=200, batch_size=16)\n",
    "#model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_val, y_val))\n",
    "model.save(\"gesture_lstm_model_v1.h5\")\n",
    "print(\"✅ Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def isStatic(landmark_history,threshold=10):\n",
    "    if len(landmark_history)<2:\n",
    "        return True\n",
    "    distance=np.mean(np.linalg.norm(np.array(landmark_history[-1])-np.array(landmark_history[-2])))\n",
    "    return distance<threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Static Gestures: ['Fist', 'fuck off', 'Open Palm', 'Spiderman', 'Thumbs Up', 'Thumbs Down', 'Victory']\n",
      "Loaded Dynamic Gestures: ['I am Inavatable', 'M Chuda', 'Time reversal', 'wave']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
      "Raw model output: [[7.93023573e-05 5.64963790e-03 9.79823172e-01 2.25909078e-03\n",
      "  7.06109358e-06 1.79180563e-06 1.21799745e-02]]\n",
      "Softmax probabilities: [[0.11516006 0.11580332 0.30676034 0.11541136 0.11515173 0.11515113\n",
      "  0.11656203]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Raw model output: [[2.4364707e-04 5.8514434e-03 9.5542049e-01 4.9378690e-03 7.8464054e-06\n",
      "  4.0404166e-06 3.3534653e-02]]\n",
      "Softmax probabilities: [[0.11570279 0.11635344 0.3007266  0.11624719 0.11567551 0.11567506\n",
      "  0.11961947]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Raw model output: [[1.1349453e-04 1.3662164e-02 6.5202224e-01 1.6466517e-02 3.1277654e-05\n",
      "  6.9309467e-06 3.1769735e-01]]\n",
      "Softmax probabilities: [[0.12014978 0.12178872 0.23059152 0.12213073 0.12013989 0.12013697\n",
      "  0.1650623 ]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Raw model output: [[8.3648488e-03 2.0832838e-03 9.7571886e-01 7.7818949e-03 3.7087139e-04\n",
      "  2.7457904e-06 5.6776023e-03]]\n",
      "Softmax probabilities: [[0.1162094  0.11548171 0.30574384 0.11614168 0.11528413 0.11524169\n",
      "  0.11589753]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Raw model output: [[8.3827419e-04 3.9143677e-04 9.9034458e-01 5.6799189e-03 2.2237045e-04\n",
      "  1.7432232e-06 2.5216506e-03]]\n",
      "Softmax probabilities: [[0.11501464 0.11496326 0.30937856 0.11557285 0.11494382 0.11491847\n",
      "  0.11520842]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Raw model output: [[9.98602991e-05 7.07558729e-03 7.19180465e-01 7.51180295e-03\n",
      "  1.09368535e-04 3.27449902e-06 2.66019672e-01]]\n",
      "Softmax probabilities: [[0.1194525  0.12028868 0.24518166 0.12034117 0.11945364 0.11944097\n",
      "  0.15584138]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Raw model output: [[5.7720015e-04 3.6407795e-04 9.9336326e-01 3.7774502e-03 3.4312230e-05\n",
      "  6.1549986e-07 1.8831234e-03]]\n",
      "Softmax probabilities: [[0.11491714 0.11489265 0.3101318  0.11528549 0.11485478 0.1148509\n",
      "  0.11506731]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Raw model output: [[2.09740759e-03 5.22569520e-03 9.33877647e-01 1.15114665e-02\n",
      "  1.77854250e-04 6.46460239e-06 4.71033640e-02]]\n",
      "Softmax probabilities: [[0.11636507 0.11672965 0.29545385 0.1174657  0.11614192 0.11612201\n",
      "  0.12172182]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Raw model output: [[1.09206535e-01 6.82720100e-04 4.08960760e-01 2.40078747e-01\n",
      "  1.39158597e-04 2.80556360e-05 2.40904018e-01]]\n",
      "Softmax probabilities: [[0.1366025  0.12255397 0.18434878 0.15570255 0.12248738 0.12247376\n",
      "  0.15583108]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Raw model output: [[5.4535218e-07 9.2198997e-07 9.1254705e-01 1.4769859e-03 5.1478751e-06\n",
      "  4.6244787e-07 8.5968882e-02]]\n",
      "Softmax probabilities: [[0.11652415 0.1165242  0.29022172 0.11669633 0.11652469 0.11652415\n",
      "  0.12698475]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Raw model output: [[9.98921037e-01 4.58202012e-05 3.12576303e-05 1.03691955e-05\n",
      "  1.86242323e-06 7.22425102e-06 9.82304220e-04]]\n",
      "Softmax probabilities: [[0.31152093 0.11473113 0.11472946 0.11472706 0.11472608 0.11472671\n",
      "  0.11483862]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Raw model output: [[9.9901783e-01 3.3001339e-05 2.5076779e-05 1.3106497e-05 2.1058395e-06\n",
      "  8.6172422e-06 9.0020179e-04]]\n",
      "Softmax probabilities: [[0.31154513 0.11472747 0.11472657 0.11472519 0.11472393 0.11472468\n",
      "  0.11482701]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Raw model output: [[5.8438189e-07 1.6434659e-06 9.9244279e-01 2.3005198e-04 2.8698454e-07\n",
      "  4.5897085e-08 7.3246146e-03]]\n",
      "Softmax probabilities: [[0.1148713  0.11487142 0.30990148 0.11489765 0.11487126 0.11487123\n",
      "  0.1157157 ]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Raw model output: [[1.28832999e-05 8.01968016e-03 8.75208497e-01 1.21300565e-02\n",
      "  1.80718598e-06 3.26373140e-07 1.04626782e-01]]\n",
      "Softmax probabilities: [[0.11723559 0.11817803 0.2812886  0.11866479 0.11723428 0.11723411\n",
      "  0.13016455]]\n",
      "Predicted index: 2\n",
      "Predicted gesture: -0.2151748538017273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Raw model output: [[7.73026386e-06 2.00952217e-03 2.17159361e-01 1.01979645e-02\n",
      "  1.20883087e-05 3.81499922e-06 7.70609558e-01]]\n",
      "Softmax probabilities: [[0.11882347 0.11906157 0.147642   0.1200405  0.11882399 0.11882301\n",
      "  0.25678542]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Raw model output: [[9.9372286e-01 8.8326240e-05 1.8961454e-04 8.3118728e-05 8.0950385e-06\n",
      "  8.2060236e-05 5.8259973e-03]]\n",
      "Softmax probabilities: [[0.31022123 0.11485279 0.11486442 0.11485219 0.11484358 0.11485207\n",
      "  0.11551367]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Raw model output: [[9.9901092e-01 2.0789696e-05 2.4216142e-05 1.4087121e-05 1.3314129e-06\n",
      "  1.8942306e-05 9.0971991e-04]]\n",
      "Softmax probabilities: [[0.31154343 0.11472624 0.11472663 0.11472546 0.114724   0.11472602\n",
      "  0.11482827]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Raw model output: [[7.9981959e-01 1.0329627e-01 1.0002050e-02 1.6198479e-05 2.1861126e-06\n",
      "  1.2580369e-06 8.6862445e-02]]\n",
      "Softmax probabilities: [[0.26380536 0.13145812 0.11974853 0.11855869 0.11855703 0.11855692\n",
      "  0.1293154 ]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Raw model output: [[9.9398202e-01 2.7895132e-03 6.1141167e-05 2.9314877e-05 8.2589941e-06\n",
      "  3.0666736e-06 3.1266739e-03]]\n",
      "Softmax probabilities: [[0.31028622 0.11515772 0.11484396 0.11484031 0.1148379  0.1148373\n",
      "  0.11519656]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Raw model output: [[9.8238420e-01 1.0709127e-02 1.4254793e-04 4.4761804e-05 2.8270437e-05\n",
      "  4.1374665e-06 6.6870665e-03]]\n",
      "Softmax probabilities: [[0.30739626 0.11633369 0.11511092 0.11509965 0.11509776 0.11509497\n",
      "  0.11586673]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Raw model output: [[9.58233297e-01 2.76071467e-02 3.89835652e-04 7.43380369e-05\n",
      "  1.19811826e-04 1.32784935e-05 1.35622695e-02]]\n",
      "Softmax probabilities: [[0.3014206  0.11885217 0.11566097 0.11562448 0.11562974 0.11561742\n",
      "  0.11719459]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Raw model output: [[9.6879435e-01 1.6633106e-02 4.0706233e-04 1.0328774e-04 8.8907327e-05\n",
      "  1.0277254e-05 1.3963029e-02]]\n",
      "Softmax probabilities: [[0.3040275  0.11732607 0.11543769 0.11540264 0.11540098 0.11539189\n",
      "  0.11701322]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Raw model output: [[9.4990432e-01 1.8961558e-03 2.9812714e-03 5.0064367e-03 3.1133273e-04\n",
      "  2.3600708e-04 3.9664503e-02]]\n",
      "Softmax probabilities: [[0.29936895 0.11600909 0.11613505 0.11637048 0.11582538 0.11581667\n",
      "  0.12047435]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Raw model output: [[9.6508080e-01 1.3186196e-03 1.9563632e-03 2.6483843e-03 2.2065145e-04\n",
      "  2.2459566e-04 2.8550487e-02]]\n",
      "Softmax probabilities: [[0.30310598 0.11562132 0.11569509 0.11577518 0.11549444 0.1154949\n",
      "  0.11881317]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Raw model output: [[9.5830643e-01 1.4184755e-03 2.8745767e-03 3.5191088e-03 3.2500995e-04\n",
      "  3.2622507e-04 3.3230178e-02]]\n",
      "Softmax probabilities: [[0.30143535 0.1157772  0.1159459  0.11602066 0.11565067 0.11565081\n",
      "  0.11951947]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Raw model output: [[9.5144373e-01 1.8979340e-03 3.6464441e-03 3.7005274e-03 4.0722240e-04\n",
      "  3.9638946e-04 3.8507756e-02]]\n",
      "Softmax probabilities: [[0.29974705 0.11597715 0.11618011 0.1161864  0.11580439 0.11580313\n",
      "  0.12030172]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Raw model output: [[9.8546183e-01 2.0057047e-03 1.0495660e-03 7.2869955e-04 8.3096733e-05\n",
      "  9.1031907e-05 1.0580072e-02]]\n",
      "Softmax probabilities: [[0.30816168 0.11525748 0.11514732 0.11511038 0.11503609 0.11503701\n",
      "  0.11624999]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Raw model output: [[9.9245292e-01 2.4714475e-03 5.6441793e-05 1.1976478e-05 3.9970491e-06\n",
      "  7.2444573e-07 5.0024814e-03]]\n",
      "Softmax probabilities: [[0.30990437 0.11515538 0.11487761 0.11487251 0.11487159 0.11487121\n",
      "  0.11544722]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Raw model output: [[9.8158824e-01 5.1851440e-03 2.3794215e-04 6.9273112e-05 3.8983268e-05\n",
      "  2.1793498e-06 1.2878189e-02]]\n",
      "Softmax probabilities: [[0.3071981  0.11571032 0.11513928 0.11511987 0.11511639 0.11511215\n",
      "  0.11660391]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Raw model output: [[9.5907831e-01 1.0803798e-03 1.4151189e-03 2.6462730e-03 1.2806692e-04\n",
      "  7.3448311e-05 3.5578407e-02]]\n",
      "Softmax probabilities: [[0.30162215 0.11572044 0.11575917 0.11590178 0.11561028 0.11560396\n",
      "  0.11978221]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Raw model output: [[9.5412982e-01 9.2062965e-04 1.5750972e-03 2.2115116e-03 1.2412042e-04\n",
      "  1.0420486e-04 4.0934637e-02]]\n",
      "Softmax probabilities: [[0.30040145 0.11580534 0.11588115 0.11595491 0.11571313 0.11571082\n",
      "  0.12053311]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Raw model output: [[9.6161133e-01 9.5047295e-04 1.7937727e-03 2.2009085e-03 1.5104309e-04\n",
      "  1.3012013e-04 3.3162318e-02]]\n",
      "Softmax probabilities: [[0.3022474  0.11565193 0.1157495  0.11579664 0.11555951 0.1155571\n",
      "  0.11943793]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Raw model output: [[9.3587834e-01 9.6203131e-04 4.4553806e-03 3.4371808e-03 2.5527953e-04\n",
      "  6.7632453e-04 5.4335419e-02]]\n",
      "Softmax probabilities: [[0.29592854 0.11618708 0.11659367 0.11647502 0.116105   0.1161539\n",
      "  0.12255684]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Raw model output: [[9.5836085e-01 8.1908354e-04 3.0171261e-03 2.3181187e-03 1.7183700e-04\n",
      "  3.4515685e-04 3.4967896e-02]]\n",
      "Softmax probabilities: [[0.3014467  0.11570588 0.11596049 0.11587947 0.11563102 0.11565106\n",
      "  0.11972534]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Raw model output: [[9.8532188e-01 7.0920680e-04 1.9261127e-04 2.3439450e-05 1.4261217e-05\n",
      "  5.2888998e-07 1.3738108e-02]]\n",
      "Softmax probabilities: [[0.30812562 0.11511078 0.11505132 0.11503187 0.11503081 0.11502923\n",
      "  0.11662035]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Raw model output: [[3.5421941e-05 9.1827176e-05 3.2691832e-04 6.4724300e-05 4.0906059e-05\n",
      "  3.4340050e-07 9.9943978e-01]]\n",
      "Softmax probabilities: [[0.11471821 0.1147247  0.11475167 0.11472158 0.11471884 0.11471419\n",
      "  0.31165072]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Raw model output: [[1.0812504e-05 6.0202674e-05 3.1259362e-04 1.7971297e-04 9.0718342e-05\n",
      "  4.1502952e-07 9.9934560e-01]]\n",
      "Softmax probabilities: [[0.11471754 0.11472321 0.11475217 0.11473691 0.11472671 0.11471634\n",
      "  0.3116272 ]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Raw model output: [[1.26672530e-08 1.45872855e-05 4.41414231e-05 2.27077486e-04\n",
      "  3.27641494e-04 9.48473442e-08 9.99386430e-01]]\n",
      "Softmax probabilities: [[0.11471537 0.11471704 0.11472044 0.11474142 0.11475296 0.11471538\n",
      "  0.3116374 ]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Raw model output: [[2.4994604e-08 3.5085272e-05 1.2708649e-04 5.8642548e-04 1.2474699e-03\n",
      "  3.1162486e-07 9.9800354e-01]]\n",
      "Softmax probabilities: [[0.11474658 0.1147506  0.11476116 0.11481388 0.11488981 0.11474661\n",
      "  0.3112914 ]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Raw model output: [[1.38923655e-08 5.06289443e-03 1.72106072e-03 3.15993937e-04\n",
      "  3.39541852e-01 1.68336862e-06 6.53356552e-01]]\n",
      "Softmax probabilities: [[0.11999901 0.12060809 0.12020572 0.12003693 0.16851512 0.11999921\n",
      "  0.23063585]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Raw model output: [[5.0561098e-09 5.5449116e-03 3.9228797e-04 4.3539985e-05 9.1401136e-01\n",
      "  4.1117445e-07 8.0007538e-02]]\n",
      "Softmax probabilities: [[0.11650123 0.11714903 0.11654695 0.11650631 0.29059    0.11650129\n",
      "  0.12620524]]\n",
      "Predicted index: 4\n",
      "Predicted gesture: -0.1900433152914047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Raw model output: [[9.3604795e-09 1.3971509e-03 1.1351383e-03 6.0214743e-04 8.8614628e-02\n",
      "  1.3385667e-06 9.0824962e-01]]\n",
      "Softmax probabilities: [[0.11660755 0.11677058 0.11673999 0.11667778 0.12741235 0.1166077\n",
      "  0.28918415]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Raw model output: [[6.9628188e-09 9.4477448e-04 1.2233504e-03 9.6192752e-04 5.8015339e-02\n",
      "  1.3373734e-06 9.3885326e-01]]\n",
      "Softmax probabilities: [[0.11601047 0.11612014 0.11615248 0.11612213 0.12293992 0.11601064\n",
      "  0.2966443 ]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Raw model output: [[5.4853997e-09 2.6853264e-03 1.3865250e-03 3.8606481e-04 2.6108477e-01\n",
      "  1.1828502e-06 7.3445624e-01]]\n",
      "Softmax probabilities: [[0.11923002 0.11955062 0.11939545 0.11927606 0.15480083 0.11923017\n",
      "  0.24851689]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Raw model output: [[5.5139244e-09 2.7817411e-03 1.2737614e-03 3.5275443e-04 2.0837106e-01\n",
      "  1.2872854e-06 7.8721946e-01]]\n",
      "Softmax probabilities: [[0.11857666 0.11890697 0.1187278  0.1186185  0.14604732 0.11857682\n",
      "  0.26054594]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Raw model output: [[2.93393243e-09 7.73417111e-03 6.26672932e-04 5.09139718e-05\n",
      "  8.66918802e-01 2.91216111e-07 1.24669105e-01]]\n",
      "Softmax probabilities: [[0.11736009 0.11827129 0.11743366 0.11736606 0.2792663  0.11736013\n",
      "  0.13294241]]\n",
      "Predicted index: 4\n",
      "Predicted gesture: -0.1900433152914047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Raw model output: [[4.1553001e-09 1.0223113e-02 7.8664511e-04 7.0811504e-05 9.0090245e-01\n",
      "  4.4531640e-07 8.8016562e-02]]\n",
      "Softmax probabilities: [[0.11675472 0.11795444 0.11684661 0.11676299 0.28742957 0.11675477\n",
      "  0.12749688]]\n",
      "Predicted index: 4\n",
      "Predicted gesture: -0.1900433152914047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Raw model output: [[0.0404526  0.8771293  0.01985713 0.04173118 0.00371642 0.00103701\n",
      "  0.01607627]]\n",
      "Softmax probabilities: [[0.12208855 0.28186363 0.11959979 0.12224475 0.11768486 0.11736996\n",
      "  0.11914846]]\n",
      "Predicted index: 1\n",
      "Predicted gesture: -0.2206867784261703\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Raw model output: [[0.06134067 0.82243407 0.01460803 0.07702265 0.00755498 0.00143185\n",
      "  0.01560787]]\n",
      "Softmax probabilities: [[0.12569848 0.26907212 0.1199594  0.12768522 0.11911629 0.11838916\n",
      "  0.12007941]]\n",
      "Predicted index: 1\n",
      "Predicted gesture: -0.2206867784261703\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Raw model output: [[4.4108042e-03 9.6616077e-01 4.3715755e-03 1.4495977e-02 6.0049524e-03\n",
      "  5.0870673e-04 4.0471437e-03]]\n",
      "Softmax probabilities: [[0.11595944 0.3033813  0.11595489 0.11713483 0.11614444 0.11550784\n",
      "  0.11591728]]\n",
      "Predicted index: 1\n",
      "Predicted gesture: -0.2206867784261703\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Raw model output: [[2.4846785e-03 9.8613936e-01 2.2685549e-03 5.1955017e-03 2.2123065e-03\n",
      "  2.3262946e-04 1.4669526e-03]]\n",
      "Softmax probabilities: [[0.11529809 0.3083315  0.11527318 0.11561107 0.11526669 0.11503873\n",
      "  0.11518081]]\n",
      "Predicted index: 1\n",
      "Predicted gesture: -0.2206867784261703\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Raw model output: [[5.6180283e-03 9.8108667e-01 3.4861227e-03 6.6241976e-03 1.2485292e-03\n",
      "  3.7897247e-04 1.5575032e-03]]\n",
      "Softmax probabilities: [[0.11577223 0.3070754  0.11552569 0.11588879 0.11526747 0.11516729\n",
      "  0.1153031 ]]\n",
      "Predicted index: 1\n",
      "Predicted gesture: -0.2206867784261703\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Raw model output: [[4.3848674e-03 9.8092216e-01 3.1630008e-03 7.0625814e-03 2.4721473e-03\n",
      "  7.3314569e-04 1.2621612e-03]]\n",
      "Softmax probabilities: [[0.11563323 0.30703467 0.11549204 0.11594329 0.11541228 0.11521176\n",
      "  0.11527272]]\n",
      "Predicted index: 1\n",
      "Predicted gesture: -0.2206867784261703\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Raw model output: [[0.6045283  0.2181887  0.04927305 0.08862417 0.00531835 0.00662361\n",
      "  0.02744374]]\n",
      "Softmax probabilities: [[0.2216721  0.15063502 0.12722331 0.13232951 0.12175237 0.1219114\n",
      "  0.12447622]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Raw model output: [[0.7773634  0.13687216 0.01848264 0.04118251 0.00342684 0.00460184\n",
      "  0.01807066]]\n",
      "Softmax probabilities: [[0.25872615 0.13635734 0.12113303 0.12391418 0.11932293 0.11946322\n",
      "  0.12108313]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Raw model output: [[0.71308506 0.2065233  0.0192433  0.0342012  0.0047169  0.00697511\n",
      "  0.0152551 ]]\n",
      "Softmax probabilities: [[0.24431533 0.14721556 0.12207285 0.12391253 0.12031239 0.12058438\n",
      "  0.12158696]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Raw model output: [[0.53598946 0.39062902 0.02007907 0.02293891 0.00470468 0.01284186\n",
      "  0.01281697]]\n",
      "Softmax probabilities: [[0.2068906  0.17890048 0.12350476 0.12385847 0.12162047 0.12261415\n",
      "  0.1226111 ]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Raw model output: [[2.5567723e-02 9.6436852e-01 4.5671118e-03 1.6933031e-03 9.8123937e-04\n",
      "  8.1215199e-04 2.0099280e-03]]\n",
      "Softmax probabilities: [[0.11847613 0.3029332  0.116014   0.11568107 0.11559873 0.1155792\n",
      "  0.11571772]]\n",
      "Predicted index: 1\n",
      "Predicted gesture: -0.2206867784261703\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Raw model output: [[0.6244429  0.26172143 0.03240124 0.04385624 0.00641386 0.01525023\n",
      "  0.01591414]]\n",
      "Softmax probabilities: [[0.22545408 0.15686649 0.12472045 0.12615733 0.12152105 0.1225996\n",
      "  0.12268102]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Raw model output: [[0.695389   0.21552101 0.02488657 0.02444009 0.00577415 0.02286729\n",
      "  0.01112194]]\n",
      "Softmax probabilities: [[0.24048932 0.14883044 0.12299863 0.12294373 0.12067015 0.12275052\n",
      "  0.12131721]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Raw model output: [[0.3631121  0.44594425 0.06179525 0.02077492 0.01209525 0.08951814\n",
      "  0.00676007]]\n",
      "Softmax probabilities: [[0.1754032  0.19055092 0.12977089 0.12455536 0.12347893 0.13341884\n",
      "  0.1228219 ]]\n",
      "Predicted index: 1\n",
      "Predicted gesture: -0.2206867784261703\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Raw model output: [[0.7048039  0.10748532 0.05698125 0.08443215 0.00503916 0.00967581\n",
      "  0.03158245]]\n",
      "Softmax probabilities: [[0.24289595 0.13366205 0.1270792  0.13061595 0.12064694 0.12120763\n",
      "  0.12389219]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Raw model output: [[0.8052329  0.07476839 0.02970299 0.04559143 0.00556188 0.011506\n",
      "  0.0276363 ]]\n",
      "Softmax probabilities: [[0.2651731  0.12772997 0.12210153 0.12405702 0.11918917 0.11989975\n",
      "  0.12184944]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Raw model output: [[0.71684515 0.16199069 0.03549883 0.02328785 0.012379   0.02128554\n",
      "  0.02871296]]\n",
      "Softmax probabilities: [[0.24536462 0.14087752 0.12413864 0.122632   0.1213015  0.12238671\n",
      "  0.1232991 ]]\n",
      "Predicted index: 0\n",
      "Predicted gesture: -0.2371041029691696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Raw model output: [[0.43884796 0.50327724 0.0163867  0.00565323 0.00925851 0.00732769\n",
      "  0.01924861]]\n",
      "Softmax probabilities: [[0.18768686 0.20017746 0.12301591 0.12170258 0.12214215 0.12190654\n",
      "  0.12336847]]\n",
      "Predicted index: 1\n",
      "Predicted gesture: -0.2206867784261703\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Raw model output: [[5.0150722e-10 1.4207694e-06 1.1959497e-05 1.8113195e-04 4.3998957e-06\n",
      "  6.3633230e-08 9.9980110e-01]]\n",
      "Softmax probabilities: [[0.11470599 0.11470616 0.11470737 0.11472677 0.1147065  0.114706\n",
      "  0.31174117]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Raw model output: [[7.1509415e-10 1.7296946e-06 1.5616233e-05 3.5384914e-04 6.1938199e-06\n",
      "  9.6184124e-08 9.9962246e-01]]\n",
      "Softmax probabilities: [[0.11471004 0.11471024 0.11471184 0.11475065 0.11471076 0.11471006\n",
      "  0.3116965 ]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Raw model output: [[3.8385239e-10 1.6421917e-06 7.0840156e-06 1.5064111e-04 6.3159828e-06\n",
      "  3.6441850e-08 9.9983430e-01]]\n",
      "Softmax probabilities: [[0.11470524 0.11470544 0.11470605 0.11472252 0.11470596 0.11470525\n",
      "  0.3117495 ]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Raw model output: [[2.0554514e-10 9.2786087e-07 5.6647295e-06 1.4723297e-04 2.8696447e-06\n",
      "  2.5830234e-08 9.9984324e-01]]\n",
      "Softmax probabilities: [[0.11470504 0.11470515 0.11470569 0.11472193 0.11470536 0.11470504\n",
      "  0.31175172]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Raw model output: [[1.6733660e-10 1.0243978e-06 9.7550710e-06 1.0436649e-03 8.1650123e-06\n",
      "  4.5173429e-08 9.9893731e-01]]\n",
      "Softmax probabilities: [[0.11472551 0.11472562 0.11472663 0.1148453  0.11472644 0.11472551\n",
      "  0.311525  ]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Raw model output: [[1.6182750e-10 1.3658781e-06 7.6932238e-06 7.4171415e-04 1.1201765e-05\n",
      "  4.0706755e-08 9.9923790e-01]]\n",
      "Softmax probabilities: [[0.11471873 0.11471888 0.11471961 0.11480385 0.11472001 0.11471874\n",
      "  0.31160024]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Raw model output: [[1.2053498e-10 1.6022231e-06 6.4800988e-06 7.3715352e-04 1.0071649e-05\n",
      "  3.1103301e-08 9.9924469e-01]]\n",
      "Softmax probabilities: [[0.11471857 0.11471876 0.11471932 0.11480317 0.11471973 0.11471857\n",
      "  0.31160194]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Raw model output: [[1.8154614e-10 1.6481357e-06 1.1387972e-05 1.2557727e-03 1.5110384e-05\n",
      "  4.4434827e-08 9.9871600e-01]]\n",
      "Softmax probabilities: [[0.1147305  0.11473069 0.1147318  0.11487466 0.11473224 0.1147305\n",
      "  0.3114696 ]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Raw model output: [[2.2220051e-10 2.0646228e-06 1.4075068e-05 1.6386275e-03 2.1396805e-05\n",
      "  5.1386863e-08 9.9832374e-01]]\n",
      "Softmax probabilities: [[0.11473934 0.11473957 0.11474095 0.11492751 0.11474179 0.11473934\n",
      "  0.31137145]]\n",
      "Predicted index: 6\n",
      "Predicted gesture: -0.1873284131288528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Raw model output: [[1.0751159e-04 4.4512386e-03 5.9270891e-03 9.7375160e-01 1.7483773e-04\n",
      "  1.8112207e-05 1.5569605e-02]]\n",
      "Softmax probabilities: [[0.11529604 0.11579794 0.11596896 0.30525488 0.1153038  0.11528573\n",
      "  0.11709261]]\n",
      "Predicted index: 3\n",
      "Predicted gesture: -0.1909535676240921\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Raw model output: [[5.9144467e-04 2.0279710e-03 3.9099697e-03 9.8372400e-01 5.6441693e-04\n",
      "  2.3740428e-04 8.9447312e-03]]\n",
      "Softmax probabilities: [[0.11513331 0.11529882 0.11551601 0.3077301  0.1151302  0.11509255\n",
      "  0.11609908]]\n",
      "Predicted index: 3\n",
      "Predicted gesture: -0.1909535676240921\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Raw model output: [[4.0044484e-04 2.8879778e-03 4.2142929e-03 9.8682404e-01 5.0898810e-04\n",
      "  2.2557711e-04 4.9386839e-03]]\n",
      "Softmax probabilities: [[0.11504275 0.11532928 0.11548235 0.3085017  0.11505524 0.11502264\n",
      "  0.11556603]]\n",
      "Predicted index: 3\n",
      "Predicted gesture: -0.1909535676240921\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Raw model output: [[3.1578902e-04 3.5734149e-03 6.9581592e-03 9.8338717e-01 5.6116114e-04\n",
      "  2.9002863e-04 4.9143126e-03]]\n",
      "Softmax probabilities: [[0.11510913 0.11548473 0.11587627 0.30764666 0.11513738 0.11510617\n",
      "  0.11563968]]\n",
      "Predicted index: 3\n",
      "Predicted gesture: -0.1909535676240921\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Raw model output: [[2.7905780e-04 3.8709163e-03 8.5233767e-03 9.8172504e-01 5.1450921e-04\n",
      "  2.5887933e-04 4.8281569e-03]]\n",
      "Softmax probabilities: [[0.11514154 0.11555586 0.11609474 0.3072335  0.11516865 0.11513922\n",
      "  0.11566652]]\n",
      "Predicted index: 3\n",
      "Predicted gesture: -0.1909535676240921\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Raw model output: [[3.1804695e-04 5.5139866e-03 7.2196997e-03 9.8007548e-01 8.0893311e-04\n",
      "  3.1237878e-04 5.7514599e-03]]\n",
      "Softmax probabilities: [[0.11518245 0.11578249 0.11598015 0.30682415 0.11523901 0.1151818\n",
      "  0.11580998]]\n",
      "Predicted index: 3\n",
      "Predicted gesture: -0.1909535676240921\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from tensorflow import keras\n",
    "from collections import deque\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load Static Gesture Model (CNN)\n",
    "static_model = keras.models.load_model(\"gesture_model.keras\")\n",
    "\n",
    "# Load Dynamic Gesture Model (3D CNN)\n",
    "dynamic_model = keras.models.load_model(\"gesture_lstm_model_v1.h5\")\n",
    "\n",
    "# Load Label Encoder for Gesture Labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_classes = np.load(\"label_classes.npy\", allow_pickle=True)\n",
    "label_encoder.classes_ = label_classes  # Assign loaded labels\n",
    "\n",
    "# Define Gesture Labels (Update according to your dataset)\n",
    "STATIC_GESTURES = [\"Fist\", \"fuck off\", \"Open Palm\", \"Spiderman\", \"Thumbs Up\", \"Thumbs Down\", \"Victory\"]\n",
    "DYNAMIC_GESTURES = [\"I am Inavatable\",\"M Chuda\",\"Time reversal\",\"wave\"]\n",
    "\n",
    "# Debug: Print loaded gestures\n",
    "print(\"Loaded Static Gestures:\", STATIC_GESTURES)\n",
    "print(\"Loaded Dynamic Gestures:\", DYNAMIC_GESTURES)\n",
    "\n",
    "# Initialize Mediapipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.5)\n",
    "\n",
    "# Store last 30 frames of landmarks\n",
    "landmark_history = deque(maxlen=30)\n",
    "\n",
    "# Function to detect if hand is static\n",
    "def isStatic(landmark_history, threshold=0.1):  # Lowered threshold for better sensitivity\n",
    "    \"\"\"Check if hand is static by comparing last two frames.\"\"\"\n",
    "    if len(landmark_history) < 2:\n",
    "        return True  # Assume static if not enough frames\n",
    "\n",
    "    # Compute Euclidean distance between last two frames\n",
    "    distance = np.linalg.norm(np.array(landmark_history[-1]) - np.array(landmark_history[-2]))\n",
    "\n",
    "    return distance < threshold  # If movement is below threshold, it's static\n",
    "\n",
    "# Start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(rgb_frame)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Extract landmarks (21 points, each with x, y, z)\n",
    "            landmarks = []\n",
    "            for lm in hand_landmarks.landmark:\n",
    "                landmarks.extend([lm.x, lm.y, lm.z])\n",
    "\n",
    "            # Store in history\n",
    "            landmark_history.append(landmarks)\n",
    "\n",
    "            # Check if static or dynamic\n",
    "            if isStatic(landmark_history):\n",
    "                if len(landmarks) == 63:  # Ensure correct shape\n",
    "                    landmarks_array = np.array(landmarks).reshape(1, -1).astype(np.float32)\n",
    "\n",
    "                    # Make prediction\n",
    "                    prediction = static_model.predict(landmarks_array)\n",
    "                    print(\"Raw model output:\", prediction)  # Print raw model output\n",
    "\n",
    "                    # Convert logits to probabilities (only if your model doesn't already output probabilities)\n",
    "                    if prediction.shape[1] > 1:  # Check if multi-class\n",
    "                        prediction_prob = keras.activations.softmax(keras.backend.variable(prediction)).numpy()\n",
    "                    else:\n",
    "                        prediction_prob = prediction  # If already probabilities\n",
    "\n",
    "                    print(\"Softmax probabilities:\", prediction_prob)  # Debug print\n",
    "\n",
    "                    # Get predicted class index\n",
    "                    predicted_index = np.argmax(prediction_prob)\n",
    "                    print(\"Predicted index:\", predicted_index)  # Debug print\n",
    "\n",
    "                    # Ensure the index is valid\n",
    "                    if 0 <= predicted_index < len(label_encoder.classes_):\n",
    "                        gesture = label_encoder.inverse_transform([predicted_index])[0]\n",
    "                    else:\n",
    "                        gesture = \"Unknown\"\n",
    "\n",
    "                    print(\"Predicted gesture:\", gesture)  # Debug print\n",
    "\n",
    "\n",
    "                    # Ensure valid index\n",
    "                    if 0 <= predicted_index < len(label_encoder.classes_):\n",
    "                        if(predicted_index==0):\n",
    "                            gesture=\"fist\"\n",
    "                        if(predicted_index==1):\n",
    "                            gesture=\"fuck off\"\n",
    "                        if(predicted_index==2):\n",
    "                            gesture=\"open palm\" \n",
    "                        if(predicted_index==3):\n",
    "                            gesture=\"spiderman\"\n",
    "                        if(predicted_index==5):\n",
    "                            gesture=\"thumbs upp\"\n",
    "                        if(predicted_index==6):\n",
    "                            gesture=\"thumbs down\"\n",
    "                        if(predicted_index==6):\n",
    "                            gesture=\"victory\"  \n",
    "                        #gesture = label_encoder.inverse_transform([predicted_index])[0]\n",
    "                    else:\n",
    "                        gesture = \"thumbs down\"\n",
    "\n",
    "                    # Display static gesture\n",
    "                    cv2.putText(frame, \"Static\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, f\"Gesture: {gesture}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                else:\n",
    "                    cv2.putText(frame, \"Error: Landmark Shape\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            else:\n",
    "                # Check if buffer is full for dynamic gesture classification\n",
    "                if len(landmark_history) == FRAME_BUFFER_SIZE:\n",
    "                    landmark_array = np.array(landmark_history)  # Shape (30, 63)\n",
    "                    '''\n",
    "                    # Add a column of zeros to make it (30, 64)\n",
    "                    extra_feature = np.zeros((FRAME_BUFFER_SIZE, 1))  \n",
    "                    landmark_array = np.hstack((landmark_array, extra_feature))  # Now shape (30, 64)'''\n",
    "\n",
    "                    dynamic_input = landmark_array.reshape(1, 30, 63)  # Ensure (1, 30, 64)\n",
    "                    dynamic_prediction = dynamic_model.predict(dynamic_input)\n",
    "                    dynamic_index = np.argmax(dynamic_prediction)\n",
    "\n",
    "\n",
    "                    if 0 <= dynamic_index < len(DYNAMIC_GESTURES):\n",
    "                        dynamic_gesture = DYNAMIC_GESTURES[dynamic_index]\n",
    "                    else:\n",
    "                        dynamic_gesture = \"Unknown\"\n",
    "\n",
    "\n",
    "                    # Display Dynamic Gesture\n",
    "                    cv2.putText(frame, \"Dynamic Gesture\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                    cv2.putText(frame, f\"Gesture: {dynamic_gesture}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Hand Gesture Recognition\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to exit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
